# RESUMO DE IMPLEMENTAÃ‡ÃƒO - Hadoop B1

## âœ… Tudo que foi Implementado

### 1. Quinta ConfiguraÃ§Ã£o (Speculative Execution)

**LocalizaÃ§Ã£o**: `config/teste5_speculative/mapred-site.xml`

**ParÃ¢metros**:
- `mapreduce.map.speculative=true`
- `mapreduce.reduce.speculative=true`
- `mapreduce.job.speculative.speculativecap=0.1` (10% mÃ¡ximo)
- `mapreduce.job.speculative.slowtaskthreshold=1.0`

**Objetivo**: Reduzir impacto de stragglers (tasks lentas) executando cÃ³pias especulativas

---

### 2. Gerador de Dataset Massivo

**Script**: `scripts/generate_large_dataset.sh`

**Recursos**:
- Gera dataset configurÃ¡vel (padrÃ£o: 500MB)
- 10 arquivos distribuÃ­dos para paralelizaÃ§Ã£o
- Biblioteca expandida (500+ palavras)
- Garante execuÃ§Ã£o de 3-4+ minutos
- GeraÃ§Ã£o paralela para velocidade

**Uso**:
```bash
./scripts/generate_large_dataset.sh 500  # 500MB
./scripts/generate_large_dataset.sh 1000 # 1GB
```

---

### 3. Testes de TolerÃ¢ncia a Falhas

**Script**: `scripts/test_fault_tolerance.sh`

**CenÃ¡rios**:
1. **Baseline**: ExecuÃ§Ã£o normal sem falhas
2. **Falha 1 Worker**: Worker2 parado durante execuÃ§Ã£o
3. **Falha 2 Workers**: Ambos workers parados durante execuÃ§Ã£o
4. **Scale Up**: Worker adicionado durante execuÃ§Ã£o

**MÃ©tricas Coletadas**:
- Status do cluster antes/durante/depois
- Tempo de execuÃ§Ã£o por cenÃ¡rio
- Momento da falha/adiÃ§Ã£o
- Logs de monitoramento contÃ­nuo
- Re-escalonamento de tasks

**EvidÃªncias**:
- `cluster_status_*.txt` - Status do cluster em cada momento
- `job_output_*.txt` - Logs completos dos jobs
- `job_monitoring.log` - Monitoramento em tempo real
- `relatorio_tolerancia_falhas.md` - RelatÃ³rio consolidado

**DuraÃ§Ã£o**: ~15-20 minutos

---

### 4. Testes de ConcorrÃªncia

**Script**: `scripts/test_concurrency.sh`

**NÃ­veis Testados**:
1. **2 Jobs Concorrentes**: ContenÃ§Ã£o moderada
2. **3 Jobs Concorrentes**: ContenÃ§Ã£o alta
3. **4 Jobs Concorrentes**: Stress test (mÃ¡xima contenÃ§Ã£o)

**MÃ©tricas Coletadas**:
- Tempo individual por job
- Tempo mÃ©dio por nÃ­vel de concorrÃªncia
- Throughput agregado
- Monitoramento de recursos (YARN nodes, aplicaÃ§Ãµes)
- Timeline de execuÃ§Ã£o

**EvidÃªncias**:
- `metrics.csv` - Todas as mÃ©tricas consolidadas
- `cluster_monitoring.log` - Recursos do cluster
- `job_*/` - DiretÃ³rios individuais por job
- `relatorio_concorrencia.md` - RelatÃ³rio consolidado

**DuraÃ§Ã£o**: ~10-15 minutos

---

### 5. Sistema de Coleta de MÃ©tricas Padronizado

**Script**: `scripts/collect_metrics.sh`

**Uso**:
```bash
./scripts/collect_metrics.sh <application_id> <output_dir> [dataset_size_mb]
```

**MÃ©tricas Coletadas**:

#### Temporais
- DuraÃ§Ã£o total (ms e s)
- Timestamps de inÃ­cio/fim
- Tempo por fase (Map/Reduce)

#### Throughput
- MB/s
- MB/min
- GB/hora

#### Recursos
- Containers alocados
- MemÃ³ria utilizada
- vCores utilizados

#### Performance
- Status final do job
- Progresso
- Contadores do job

#### Comparativas
- VariaÃ§Ã£o percentual vs baseline
- Melhoria/degradaÃ§Ã£o de performance

**Arquivos Gerados**:
- `metrics_summary.txt` - Resumo legÃ­vel
- `metrics_summary.csv` - Formato CSV
- `temporal_metrics.txt` - MÃ©tricas temporais
- `throughput_metrics.txt` - Throughput
- `phase_metrics.txt` - Fases Map/Reduce
- `resource_metrics.txt` - Recursos
- `performance_metrics.txt` - Performance
- `comparative_metrics.txt` - ComparaÃ§Ã£o

---

### 6. Script Mestre (Executar Tudo)

**Script**: `scripts/run_all_tests.sh`

**Fluxo Completo**:
1. Verificar cluster Hadoop
2. Gerar dataset massivo (500MB)
3. Executar teste baseline
4. Executar teste 5 (speculative execution)
5. Executar testes de tolerÃ¢ncia a falhas (4 cenÃ¡rios)
6. Executar testes de concorrÃªncia (3 nÃ­veis)
7. Gerar relatÃ³rio final consolidado

**Uso**:
```bash
./scripts/run_all_tests.sh
```

**Interativo**: Pergunta antes de executar testes longos (falhas e concorrÃªncia)

---

## ğŸ“Š Estrutura de Resultados

```
resultados/B1/
â”œâ”€â”€ teste0_baseline/              # ConfiguraÃ§Ã£o padrÃ£o (referÃªncia)
â”‚   â”œâ”€â”€ job_output.txt
â”‚   â”œâ”€â”€ app_id.txt
â”‚   â”œâ”€â”€ time_stats.txt
â”‚   â”œâ”€â”€ metrics_summary.txt
â”‚   â”œâ”€â”€ metrics_summary.csv
â”‚   â”œâ”€â”€ temporal_metrics.txt
â”‚   â”œâ”€â”€ throughput_metrics.txt
â”‚   â”œâ”€â”€ phase_metrics.txt
â”‚   â”œâ”€â”€ resource_metrics.txt
â”‚   â”œâ”€â”€ performance_metrics.txt
â”‚   â””â”€â”€ comparative_metrics.txt
â”‚
â”œâ”€â”€ teste5_speculative/           # Quinta configuraÃ§Ã£o (NOVO)
â”‚   â”œâ”€â”€ config.txt                # ConfiguraÃ§Ã£o XML utilizada
â”‚   â”œâ”€â”€ resumo.txt                # Resumo do teste
â”‚   â””â”€â”€ [mesmos arquivos de mÃ©tricas]
â”‚
â”œâ”€â”€ teste_tolerancia_falhas/      # Testes de falhas
â”‚   â””â”€â”€ run_TIMESTAMP/
â”‚       â”œâ”€â”€ relatorio_tolerancia_falhas.md
â”‚       â”œâ”€â”€ cluster_status_baseline_before.txt
â”‚       â”œâ”€â”€ cluster_status_baseline_after.txt
â”‚       â”œâ”€â”€ job_output_baseline.txt
â”‚       â”œâ”€â”€ app_id_baseline.txt
â”‚       â”œâ”€â”€ duration_baseline.txt
â”‚       â”œâ”€â”€ cluster_status_scenario2_before.txt
â”‚       â”œâ”€â”€ cluster_status_scenario2_failure.txt
â”‚       â”œâ”€â”€ cluster_status_scenario2_after.txt
â”‚       â”œâ”€â”€ job_output_scenario2.txt
â”‚       â”œâ”€â”€ job_monitoring.log
â”‚       â”œâ”€â”€ failure_timestamp_scenario2.txt
â”‚       â””â”€â”€ [arquivos similares para scenarios 3 e 4]
â”‚
â”œâ”€â”€ teste_concorrencia/           # Testes de concorrÃªncia
â”‚   â””â”€â”€ run_TIMESTAMP/
â”‚       â”œâ”€â”€ relatorio_concorrencia.md
â”‚       â”œâ”€â”€ metrics.csv
â”‚       â”œâ”€â”€ cluster_monitoring.log
â”‚       â”œâ”€â”€ job_1/
â”‚       â”‚   â”œâ”€â”€ app_id.txt
â”‚       â”‚   â”œâ”€â”€ duration.txt
â”‚       â”‚   â”œâ”€â”€ timeline.txt
â”‚       â”‚   â”œâ”€â”€ job_output.txt
â”‚       â”‚   â””â”€â”€ yarn_status.txt
â”‚       â”œâ”€â”€ job_2/
â”‚       â”œâ”€â”€ test2_3jobs/
â”‚       â”‚   â”œâ”€â”€ job_1/
â”‚       â”‚   â”œâ”€â”€ job_2/
â”‚       â”‚   â””â”€â”€ job_3/
â”‚       â””â”€â”€ test3_4jobs/
â”‚           â”œâ”€â”€ job_1/
â”‚           â”œâ”€â”€ job_2/
â”‚           â”œâ”€â”€ job_3/
â”‚           â””â”€â”€ job_4/
â”‚
â””â”€â”€ relatorio_final_completo.md   # RelatÃ³rio consolidado de tudo
```

---

## ğŸš€ Como Executar (Passo a Passo)

### PrÃ©-requisitos

```bash
cd /home/edilberto/pspd/atividade-extraclasse-2-pspd

# 1. Iniciar cluster Hadoop
cd hadoop
docker-compose up -d
cd ..

# 2. Aguardar ~30s para cluster iniciar
sleep 30

# 3. Verificar cluster
docker ps | grep hadoop
```

### OpÃ§Ã£o 1: Executar Tudo Automaticamente

```bash
./scripts/run_all_tests.sh
```

â±ï¸ **30-40 minutos** (interativo: pergunta antes de testes longos)

### OpÃ§Ã£o 2: Executar Individualmente

```bash
# Gerar dataset massivo
./scripts/generate_large_dataset.sh 500

# Teste 5: Speculative Execution (manual)
docker cp config/teste5_speculative/mapred-site.xml \
  hadoop-master:/home/hadoop/hadoop/etc/hadoop/mapred-site.xml
docker exec hadoop-master bash -c "
  /home/hadoop/hadoop/sbin/stop-yarn.sh && sleep 5 && \
  /home/hadoop/hadoop/sbin/start-yarn.sh && sleep 10
"
# Executar job e coletar mÃ©tricas...

# Testes de tolerÃ¢ncia a falhas
./scripts/test_fault_tolerance.sh

# Testes de concorrÃªncia
./scripts/test_concurrency.sh
```

---

## ğŸ“ˆ MÃ©tricas Garantidas

### Tempo de ExecuÃ§Ã£o
âœ… Tempo total (segundos)
âœ… Tempo por fase (Map, Reduce)
âœ… Timestamps de inÃ­cio/fim

### Throughput
âœ… MB/s
âœ… MB/min
âœ… GB/hora

### VariaÃ§Ã£o Percentual
âœ… ComparaÃ§Ã£o com baseline
âœ… FÃ³rmula: `(atual - baseline) / baseline Ã— 100`

### Recursos
âœ… Containers alocados
âœ… MemÃ³ria utilizada
âœ… vCores utilizados

### TolerÃ¢ncia a Falhas
âœ… DuraÃ§Ã£o com/sem falhas
âœ… Re-escalonamento de tasks
âœ… RecuperaÃ§Ã£o automÃ¡tica

### ConcorrÃªncia
âœ… Tempo individual por job
âœ… Throughput agregado
âœ… ContenÃ§Ã£o de recursos
âœ… Comportamento do scheduler

---

## ğŸ“‹ Checklist de Requisitos B1

- [x] Cluster Hadoop com 1 master + 2 workers
- [x] Interface web de monitoramento (YARN/HDFS)
- [x] Arquivos de configuraÃ§Ã£o documentados
- [x] **5 alteraÃ§Ãµes de configuraÃ§Ã£o**:
  - [x] Teste 1: MemÃ³ria YARN
  - [x] Teste 2: ReplicaÃ§Ã£o HDFS
  - [x] Teste 3: Block Size
  - [x] Teste 4: NÃºmero de Reducers
  - [x] **Teste 5: Speculative Execution (NOVO)**
- [x] Dataset massivo (3-4+ minutos de execuÃ§Ã£o)
- [x] AplicaÃ§Ã£o WordCount MapReduce
- [x] Testes de tolerÃ¢ncia a falhas:
  - [x] RemoÃ§Ã£o de workers durante execuÃ§Ã£o
  - [x] AdiÃ§Ã£o de workers durante execuÃ§Ã£o
  - [x] Monitoramento de impacto (tempo, reexecuÃ§Ã£o)
- [x] Testes de concorrÃªncia (mÃºltiplos jobs simultÃ¢neos)
- [x] MÃ©tricas padronizadas:
  - [x] Tempo de resposta
  - [x] Throughput (MB/min)
  - [x] VariaÃ§Ã£o percentual
- [x] DocumentaÃ§Ã£o de cenÃ¡rios e resultados
- [x] ConclusÃµes sobre vantagens/desvantagens

---

## ğŸ“š DocumentaÃ§Ã£o

- **Guia Completo**: [docs/GUIA_EXECUCAO_HADOOP.md](docs/GUIA_EXECUCAO_HADOOP.md)
- **README Principal**: [README.md](README.md)
- **DocumentaÃ§Ã£o Hadoop**: [docs/hadoop.md](docs/hadoop.md)
- **Testes**: [docs/tests.md](docs/tests.md)

---

## ğŸ¯ PrÃ³ximos Passos

1. **Executar os testes**:
   ```bash
   ./scripts/run_all_tests.sh
   ```

2. **Analisar resultados**:
   ```bash
   cat resultados/B1/relatorio_final_completo.md
   ```

3. **Gerar grÃ¡ficos comparativos** (opcional):
   - Usar mÃ©tricas CSV dos testes
   - Plotar tempo vs configuraÃ§Ã£o
   - Plotar throughput vs nÃ­vel de concorrÃªncia

4. **Documentar aprendizados**:
   - Anotar insights de cada teste
   - Identificar configuraÃ§Ãµes Ã³timas
   - Registrar limitaÃ§Ãµes observadas

---

**Data**: $(date '+%Y-%m-%d %H:%M:%S')
**VersÃ£o**: 1.0
**Status**: âœ… COMPLETO E PRONTO PARA USO
