# Metodologia de Testes

## ğŸ¯ Objetivos dos Testes

Os testes foram projetados para avaliar o impacto de diferentes configuraÃ§Ãµes no desempenho do cluster Hadoop, especificamente:

1. **Recursos de memÃ³ria** (YARN)
2. **ReplicaÃ§Ã£o de dados** (HDFS)
3. **Tamanho de blocos** (HDFS)
4. **ParalelizaÃ§Ã£o** (MapReduce)

## ğŸ§ª B1 - Testes Hadoop

### Dataset

- **Tamanho**: 10.000 linhas
- **ConteÃºdo**: Texto aleatÃ³rio com palavras tÃ©cnicas
- **Palavras**: hadoop, mapreduce, yarn, hdfs, spark, distributed, computing, big, data, cluster, node, worker, master, java, processing
- **GeraÃ§Ã£o**: AutomÃ¡tica via script `generate_dataset.sh`

### AplicaÃ§Ã£o de Teste

**WordCount** - AplicaÃ§Ã£o MapReduce clÃ¡ssica que conta a frequÃªncia de palavras.

**Por quÃª WordCount?**
- Carga balanceada entre Map e Reduce
- Uso intensivo de I/O (HDFS)
- FÃ¡cil validaÃ§Ã£o de resultados
- Comportamento previsÃ­vel

### Testes Realizados

#### Teste 1: MemÃ³ria YARN

**ConfiguraÃ§Ã£o Alterada:**
```xml
<property>
  <name>yarn.nodemanager.resource.memory-mb</name>
  <value>1024</value>  <!-- PadrÃ£o: 2048 -->
</property>
```

**HipÃ³tese:** Reduzir a memÃ³ria disponÃ­vel deve aumentar o tempo de execuÃ§Ã£o devido a:
- Menos containers simultÃ¢neos
- Maior uso de swap/disco
- PossÃ­vel throttling de tasks

**MÃ©tricas Observadas:**
- Tempo total de execuÃ§Ã£o
- NÃºmero de containers
- Tempo de Map
- Tempo de Reduce
- UtilizaÃ§Ã£o de memÃ³ria

#### Teste 2: ReplicaÃ§Ã£o HDFS

**ConfiguraÃ§Ã£o Alterada:**
```xml
<property>
  <name>dfs.replication</name>
  <value>1</value>  <!-- PadrÃ£o: 2 -->
</property>
```

**HipÃ³tese:** Reduzir replicaÃ§Ã£o deve:
- âœ… Diminuir tempo de escrita
- âœ… Reduzir uso de disco
- âŒ Aumentar risco de perda de dados
- â“ Impacto variÃ¡vel no tempo de leitura

**MÃ©tricas Observadas:**
- Tempo de escrita no HDFS
- Tempo de leitura no HDFS
- EspaÃ§o em disco usado
- Tempo total do job

#### Teste 3: Block Size

**ConfiguraÃ§Ã£o Alterada:**
```xml
<property>
  <name>dfs.blocksize</name>
  <value>67108864</value>  <!-- 64MB, PadrÃ£o: 128MB -->
</property>
```

**HipÃ³tese:** Blocos menores devem resultar em:
- âœ… Mais tasks Map (melhor paralelizaÃ§Ã£o)
- âŒ Mais overhead de metadados
- âŒ Maior uso de memÃ³ria no NameNode
- â“ Impacto variÃ¡vel no tempo total

**MÃ©tricas Observadas:**
- NÃºmero de blocos criados
- NÃºmero de Map tasks
- Tempo de Map
- Tempo total do job

#### Teste 4: NÃºmero de Reducers

**ConfiguraÃ§Ã£o Alterada:**
```xml
<property>
  <name>mapreduce.job.reduces</name>
  <value>4</value>  <!-- PadrÃ£o: 1 -->
</property>
```

**HipÃ³tese:** Mais reducers devem:
- âœ… Melhor paralelizaÃ§Ã£o da fase Reduce
- âœ… Reduzir tempo de Reduce
- âŒ Mais shuffle de dados
- â“ Pode nÃ£o ter impacto se dataset for pequeno

**MÃ©tricas Observadas:**
- NÃºmero de Reduce tasks
- Tempo de Shuffle
- Tempo de Reduce
- Tempo total do job

### Processo de ExecuÃ§Ã£o

Para cada teste:

1. **PreparaÃ§Ã£o**
   ```bash
   # Parar processos
   # Limpar datanodes
   # Copiar configuraÃ§Ã£o especÃ­fica
   ```

2. **InicializaÃ§Ã£o**
   ```bash
   # Formatar NameNode
   # Iniciar HDFS e YARN
   # Verificar nodes ativos
   ```

3. **ExecuÃ§Ã£o**
   ```bash
   # Gerar dataset
   # Copiar para HDFS
   # Executar WordCount
   # Coletar mÃ©tricas
   ```

4. **Coleta de Resultados**
   ```bash
   # Extrair logs do job
   # Salvar mÃ©tricas YARN/HDFS
   # Gerar resumo
   ```

### MÃ©tricas Coletadas

De cada execuÃ§Ã£o, sÃ£o extraÃ­das:

**Do Job MapReduce:**
- Job ID
- Start time / End time
- Elapsed time
- Map tasks (total, successful, failed)
- Reduce tasks (total, successful, failed)
- Map time
- Reduce time
- Shuffle time

**Do HDFS:**
- Bytes read
- Bytes written
- HDFS read operations
- HDFS write operations

**Do YARN:**
- Memory allocated
- VCores allocated
- Container preemptions

### Estrutura de Resultados

```
resultados/B1/
â”œâ”€â”€ teste1_memoria/
â”‚   â”œâ”€â”€ resumo.txt              # Resumo do teste
â”‚   â”œâ”€â”€ job_output.txt          # Output completo do MapReduce
â”‚   â””â”€â”€ relatorio.txt           # MÃ©tricas detalhadas
â”œâ”€â”€ teste2_replicacao/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ teste3_blocksize/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ teste4_reducers/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ resumo_comparativo.txt      # ComparaÃ§Ã£o entre todos
â””â”€â”€ relatorio_consolidado.txt   # AnÃ¡lise consolidada
```

## ğŸ§ª B2 - Testes Spark

### Objetivo

Implementar e validar um pipeline de streaming completo:

**Producer** â†’ **Kafka** â†’ **Spark Streaming** â†’ **Elasticsearch** â†’ **Kibana**

### Fluxo de Dados

1. **Producer Python** gera mensagens (frases aleatÃ³rias)
2. **Kafka** armazena mensagens no tÃ³pico `input-topic`
3. **Spark Streaming** consome, processa (WordCount) e envia para Elasticsearch
4. **Kibana** visualiza resultados em tempo real

### Testes de ValidaÃ§Ã£o

#### 1. Conectividade

```bash
# Zookeeper â†” Kafka
# Kafka â†” Spark
# Spark â†” Elasticsearch
# Kibana â†” Elasticsearch
```

#### 2. ProduÃ§Ã£o/Consumo Kafka

```bash
# Criar tÃ³pico
# Produzir mensagens
# Consumir mensagens
# Verificar offset
```

#### 3. Processamento Spark

```bash
# Submit job
# Verificar streaming ativo
# Monitorar logs
# Validar output
```

#### 4. Armazenamento Elasticsearch

```bash
# Verificar Ã­ndice criado
# Contar documentos
# Validar estrutura
```

#### 5. VisualizaÃ§Ã£o Kibana

```bash
# Criar index pattern
# Visualizar em Discover
# Criar dashboard
```

### MÃ©tricas Observadas

- **LatÃªncia**: Tempo entre produÃ§Ã£o e visualizaÃ§Ã£o
- **Throughput**: Mensagens/segundo processadas
- **Disponibilidade**: Uptime dos serviÃ§os
- **Escalabilidade**: Comportamento sob carga

## ğŸ“Š AnÃ¡lise de Resultados

### ComparaÃ§Ã£o de Desempenho

Para cada teste B1, compare:

```
Baseline (configuraÃ§Ã£o padrÃ£o) vs Teste Modificado

MÃ©tricas:
- Î” Tempo Total (%)
- Î” Tempo Map (%)
- Î” Tempo Reduce (%)
- Î” Uso de MemÃ³ria (%)
- Î” I/O HDFS (%)
```

### InterpretaÃ§Ã£o

**Melhoria (verde):** ConfiguraÃ§Ã£o reduziu tempo/recursos
**DegradaÃ§Ã£o (vermelho):** ConfiguraÃ§Ã£o aumentou tempo/recursos
**Neutro (amarelo):** Impacto desprezÃ­vel (<5%)

### RecomendaÃ§Ãµes

Com base nos resultados, determinar:

1. **ConfiguraÃ§Ã£o Ã³tima** para o workload especÃ­fico
2. **Trade-offs** entre desempenho e confiabilidade
3. **Escalabilidade** com aumento de dados/nodes

## ğŸ“ DocumentaÃ§Ã£o

Cada teste gera:

1. **resumo.txt**: Overview do teste
2. **job_output.txt**: Log completo do MapReduce
3. **relatorio.txt**: MÃ©tricas detalhadas

O relatÃ³rio consolidado compara todos os testes e fornece anÃ¡lise final.

## ğŸ”„ Reprodutibilidade

Todos os testes sÃ£o:
- **Automatizados**: Via scripts shell
- **DeterminÃ­sticos**: Mesmo dataset, mesmas configuraÃ§Ãµes
- **Documentados**: Logs completos preservados
- **Versionados**: ConfiguraÃ§Ãµes em Git

Para reproduzir:

```bash
./scripts/verify.sh       # Validar ambiente
./scripts/run_tests.sh    # Executar todos os testes
cat resultados/B1/resumo_comparativo.txt  # Ver resultados
```
