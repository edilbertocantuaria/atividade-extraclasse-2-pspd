# DocumentaÃ§Ã£o TÃ©cnica - Hadoop

> ğŸš€ **Para instruÃ§Ãµes de execuÃ§Ã£o**, consulte **[como_executar.md](../como_executar.md)**

> Esta documentaÃ§Ã£o contÃ©m detalhes tÃ©cnicos sobre arquitetura e configuraÃ§Ãµes Hadoop.

## ğŸ—ï¸ Arquitetura

### Topologia do Cluster

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  hadoop-master  â”‚
â”‚  - NameNode     â”‚
â”‚  - ResourceMgr  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”
â”‚worker1â”‚  â”‚worker2â”‚
â”‚DataNodeâ”‚ â”‚DataNodeâ”‚
â”‚NodeMgr â”‚ â”‚NodeMgr â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes

- **1 Master Node**: 
  - HDFS NameNode (gerencia metadados)
  - YARN ResourceManager (orquestraÃ§Ã£o de jobs)

- **2 Worker Nodes**:
  - HDFS DataNode (armazenamento)
  - YARN NodeManager (execuÃ§Ã£o de tasks)

- **Rede**: `hadoop-net` (bridge)

## âš™ï¸ ConfiguraÃ§Ãµes

### core-site.xml
```xml
<property>
  <name>fs.defaultFS</name>
  <value>hdfs://master:9000</value>
</property>
```

### hdfs-site.xml
```xml
<property>
  <name>dfs.replication</name>
  <value>2</value>
</property>
<property>
  <name>dfs.blocksize</name>
  <value>134217728</value> <!-- 128MB -->
</property>
```

### mapred-site.xml
```xml
<property>
  <name>mapreduce.framework.name</name>
  <value>yarn</value>
</property>
```

### yarn-site.xml
```xml
<property>
  <name>yarn.nodemanager.aux-services</name>
  <value>mapreduce_shuffle</value>
</property>
<property>
  <name>yarn.resourcemanager.hostname</name>
  <value>master</value>
</property>
<property>
  <name>yarn.nodemanager.resource.memory-mb</name>
  <value>2048</value>
</property>
```

## ğŸ”§ OperaÃ§Ãµes Comuns

### Iniciar Cluster
```bash
./scripts/setup.sh
```

### Verificar Status
```bash
# Via web UI
http://localhost:9870  # HDFS
http://localhost:8088  # YARN

# Via linha de comando
docker exec hadoop-master hdfs dfsadmin -report
docker exec hadoop-master yarn node -list
```

### Comandos HDFS Ãšteis
```bash
# Listar arquivos
docker exec hadoop-master hdfs dfs -ls /

# Upload de arquivo
docker exec hadoop-master hdfs dfs -put /local/file /hdfs/path

# Download de arquivo
docker exec hadoop-master hdfs dfs -get /hdfs/path /local/file

# Ver conteÃºdo
docker exec hadoop-master hdfs dfs -cat /hdfs/file

# Remover arquivo/diretÃ³rio
docker exec hadoop-master hdfs dfs -rm -r /hdfs/path
```

### Executar Job MapReduce
```bash
docker exec hadoop-master hadoop jar \
  /home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \
  wordcount \
  /user/hadoop/input \
  /user/hadoop/output
```

## ğŸ§ª Testes de ConfiguraÃ§Ã£o

O projeto inclui 4 testes automatizados que avaliam o impacto de diferentes configuraÃ§Ãµes:

### Teste 1: MemÃ³ria YARN
- **ConfiguraÃ§Ã£o**: `yarn.nodemanager.resource.memory-mb = 1024`
- **Objetivo**: Avaliar impacto da reduÃ§Ã£o de memÃ³ria
- **Arquivo**: `config/teste1_memoria/yarn-site.xml`

### Teste 2: ReplicaÃ§Ã£o HDFS
- **ConfiguraÃ§Ã£o**: `dfs.replication = 1`
- **Objetivo**: Avaliar performance sem redundÃ¢ncia
- **Arquivo**: `config/teste2_replicacao/hdfs-site.xml`

### Teste 3: Block Size
- **ConfiguraÃ§Ã£o**: `dfs.blocksize = 67108864` (64MB)
- **Objetivo**: Avaliar impacto de blocos menores
- **Arquivo**: `config/teste3_blocksize/hdfs-site.xml`

### Teste 4: NÃºmero de Reducers
- **ConfiguraÃ§Ã£o**: `mapreduce.job.reduces = 4`
- **Objetivo**: Avaliar paralelizaÃ§Ã£o na fase de reduce
- **Arquivo**: `config/teste4_reducers/mapred-site.xml`

## ğŸ” Troubleshooting

### Cluster nÃ£o inicia
```bash
# Verificar logs
docker logs hadoop-master
docker logs hadoop-worker1

# Reiniciar contÃªineres
./scripts/cleanup.sh
./scripts/setup.sh
```

### NameNode nÃ£o formata
```bash
# Limpar dados antigos
docker exec hadoop-master rm -rf /tmp/hadoop-hadoop/dfs/name/*
docker exec hadoop-master hdfs namenode -format -force
```

### DataNode nÃ£o conecta
```bash
# Verificar cluster ID
docker exec hadoop-master cat /tmp/hadoop-hadoop/dfs/name/current/VERSION
docker exec hadoop-worker1 cat /tmp/hadoop-hadoop/dfs/data/current/VERSION

# Se diferentes, limpar datanodes
docker exec hadoop-worker1 rm -rf /tmp/hadoop-hadoop/dfs/data/*
docker exec hadoop-worker2 rm -rf /tmp/hadoop-hadoop/dfs/data/*
```

### Job fica travado
```bash
# Verificar recursos YARN
docker exec hadoop-master yarn node -list
docker exec hadoop-master yarn application -list

# Matar job
docker exec hadoop-master yarn application -kill <application_id>
```

## ğŸ“Š Monitoramento

### HDFS Health
```bash
docker exec hadoop-master hdfs dfsadmin -report
```

Verifique:
- Live datanodes (deve ser 2)
- DFS Used%
- Block pool used

### YARN Resources
```bash
docker exec hadoop-master yarn node -list
```

Verifique:
- Node state (RUNNING)
- Available memory
- Available vcores

## ğŸ” SeguranÃ§a

Este cluster Ã© configurado para **desenvolvimento/testes apenas**:
- Sem autenticaÃ§Ã£o
- Sem criptografia
- Portas expostas localmente

Para produÃ§Ã£o, configure:
- Kerberos
- SSL/TLS
- Firewall
- ACLs

## ğŸ“š ReferÃªncias

- [Hadoop Documentation](https://hadoop.apache.org/docs/)
- [HDFS Architecture](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)
- [YARN Architecture](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html)
