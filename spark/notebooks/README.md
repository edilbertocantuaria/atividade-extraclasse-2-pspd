# B2 - Apache Spark: Pipeline de Processamento Streaming

## ğŸ“‹ VisÃ£o Geral

Este notebook implementa um pipeline completo de processamento de stream usando **Apache Spark Structured Streaming** com integraÃ§Ã£o **Kafka** para entrada e saÃ­da de dados, conforme especificaÃ§Ã£o do laboratÃ³rio B2.

## ğŸ¯ Objetivo

Criar um sistema de WordCount em tempo real que:
- Consome mensagens de um stream (simulando rede social)
- Processa com Spark Structured Streaming
- Gera visualizaÃ§Ãµes dinÃ¢micas dos resultados

## ğŸ“¦ Arquivo Principal

- **`B2_pipeline.ipynb`**: Notebook Jupyter auto-contido com todas as etapas

## ğŸš€ Como Executar

### OpÃ§Ã£o 1: Google Colab (Recomendado)

1. Fazer upload do notebook `B2_pipeline.ipynb` no Google Colab
2. Executar cÃ©lulas sequencialmente (`Runtime > Run all`)
3. Aguardar instalaÃ§Ã£o automÃ¡tica de dependÃªncias (~2-3 minutos)
4. Visualizar grÃ¡ficos inline

### OpÃ§Ã£o 2: Jupyter Local

```bash
# 1. Instalar dependÃªncias
pip install pyspark==3.5.0 kafka-python wordcloud matplotlib pandas numpy jupyter

# 2. Garantir Java instalado (necessÃ¡rio para Spark)
java -version  # Deve ser Java 8 ou 11

# 3. Iniciar Jupyter
jupyter notebook

# 4. Abrir B2_pipeline.ipynb e executar cÃ©lulas
```

## ğŸ“Š Estrutura do Notebook

### 1. InicializaÃ§Ãµes
- DetecÃ§Ã£o de ambiente (Colab/Local)
- InstalaÃ§Ã£o de dependÃªncias Python
- Download e setup do Apache Kafka

### 2. ConfiguraÃ§Ã£o de VisualizaÃ§Ã£o
- PreparaÃ§Ã£o de diretÃ³rios de trabalho
- Imports de bibliotecas de plots

### 3. Setup do Apache Spark
- CriaÃ§Ã£o de SparkSession com suporte Kafka
- ConfiguraÃ§Ã£o de checkpoints e memÃ³ria

### 4. Setup do Kafka
- InicializaÃ§Ã£o de Zookeeper e Kafka broker
- CriaÃ§Ã£o de tÃ³picos `social-input` e `wordcount-output`

### 5. Producer (Entrada)
**âš ï¸ AdaptaÃ§Ã£o:** Gerador de texto ao invÃ©s de Discord

- **Motivo:** APIs de redes sociais exigem tokens, configuraÃ§Ãµes externas e nÃ£o sÃ£o reproduzÃ­veis facilmente
- **SoluÃ§Ã£o:** `SocialMediaSimulator` gera mensagens automÃ¡ticas simulando posts sobre Big Data
- **Vantagens:** ReprodutÃ­vel, sem dependÃªncias externas, controle total do fluxo

### 6. ConfiguraÃ§Ã£o de SaÃ­da GrÃ¡fica
**âš ï¸ AdaptaÃ§Ã£o:** WordCloud inline ao invÃ©s de ElasticSearch/Kibana

- **Motivo:** ELK requer >4GB RAM, Docker complexo e nÃ£o Ã© viÃ¡vel no Colab
- **SoluÃ§Ã£o:** `WordCloudVisualizer` consome do Kafka e plota inline com matplotlib
- **Vantagens:** Leve, rÃ¡pido, funciona em qualquer ambiente Python

### 7. Processamento Spark Streaming
- Leitura do tÃ³pico Kafka `social-input`
- TokenizaÃ§Ã£o e limpeza (remoÃ§Ã£o de stopwords PT + EN)
- WordCount com agregaÃ§Ã£o contÃ­nua
- PublicaÃ§Ã£o de resultados no tÃ³pico `wordcount-output`

### 8. VisualizaÃ§Ã£o de Resultados
- GrÃ¡fico de barras (Top N palavras)
- Nuvem de palavras dinÃ¢mica
- AtualizaÃ§Ãµes near-real-time

### 9. ValidaÃ§Ã£o
- Status das queries Spark
- Offsets dos tÃ³picos Kafka
- EstatÃ­sticas de mensagens processadas
- Amostras de resultados

### 10. FinalizaÃ§Ã£o
- Parada de streams e producers
- Cleanup automÃ¡tico de recursos
- RelatÃ³rio final de execuÃ§Ã£o

## âš™ï¸ Tecnologias Utilizadas

| Componente | VersÃ£o | FunÃ§Ã£o |
|------------|--------|--------|
| Apache Spark | 3.5.0 | Processamento distribuÃ­do |
| Apache Kafka | 3.6.0 | Message broker |
| Scala | 2.12 | BinÃ¡rios Spark/Kafka |
| Zookeeper | (bundled) | CoordenaÃ§Ã£o Kafka |
| Python | 3.x | Linguagem principal |
| kafka-python | latest | Cliente Kafka |
| wordcloud | latest | VisualizaÃ§Ã£o |
| matplotlib | latest | Plots |

## ğŸ“ˆ Resultados Esperados

Ao final da execuÃ§Ã£o, o notebook exibirÃ¡:

1. **EstatÃ­sticas:**
   - NÃºmero de mensagens produzidas
   - Palavras Ãºnicas processadas
   - Total de contagens acumuladas

2. **VisualizaÃ§Ãµes:**
   - GrÃ¡fico de barras horizontal (Top 20-25 palavras)
   - Nuvem de palavras colorida (100-150 palavras)

3. **Monitoramento:**
   - Status das queries Spark Streaming
   - Offsets dos tÃ³picos Kafka
   - Taxa de processamento (rows/sec)

## ğŸ”§ Troubleshooting

### Erro: "No module named 'pyspark'"
```bash
pip install pyspark==3.5.0
```

### Erro: "Kafka failed to start"
- Verificar se porta 9092 estÃ¡ disponÃ­vel
- No Colab, reiniciar runtime e executar novamente

### Erro: "Java not found"
```bash
# Ubuntu/Debian
sudo apt-get install openjdk-11-jdk

# macOS
brew install openjdk@11
```

### VisualizaÃ§Ãµes nÃ£o aparecem
- Executar `%matplotlib inline` no inÃ­cio do notebook
- Reiniciar kernel e rodar novamente

## ğŸ“ Justificativas de AdaptaÃ§Ãµes

### 1. Discord â†’ Gerador AutomÃ¡tico

**EspecificaÃ§Ã£o original:** "Substituir entrada por mÃ©todo de coleta de palavras a partir de rede social como Discord"

**AdaptaÃ§Ã£o implementada:** Gerador automÃ¡tico de mensagens simulando posts de rede social

**Justificativa:**
- Discord exige criaÃ§Ã£o de bot, token API, permissions, webhooks
- Google Colab nÃ£o suporta serviÃ§os persistentes externos
- Complexidade de configuraÃ§Ã£o desvia o foco pedagÃ³gico
- **SoluÃ§Ã£o mantÃ©m conceito:** stream contÃ­nuo de mensagens via Kafka
- **Vantagens:** Reprodutibilidade total, sem dependÃªncias externas

### 2. ElasticSearch/Kibana â†’ WordCloud Inline

**EspecificaÃ§Ã£o original:** "Substituir saÃ­da por grÃ¡fico de nuvens usando ElasticSearch e Kibana"

**AdaptaÃ§Ã£o implementada:** Consumer Kafka + visualizaÃ§Ã£o inline com `wordcloud` + matplotlib

**Justificativa:**
- ELK requer >4GB RAM e setup Docker complexo
- Kibana nÃ£o Ã© scriptÃ¡vel via notebook (exige configuraÃ§Ã£o manual)
- Google Colab tem limitaÃ§Ãµes de memÃ³ria e processos externos
- **SoluÃ§Ã£o mantÃ©m conceito:** Dashboard visual de nuvem de palavras
- **Vantagens:** Leve, rÃ¡pido, atualizaÃ§Ã£o near-real-time, totalmente inline

## ğŸ“ Conceitos Demonstrados

âœ… **Spark Structured Streaming:** Processamento contÃ­nuo de dados  
âœ… **Kafka Integration:** Consumo e produÃ§Ã£o de mensagens  
âœ… **WordCount DistribuÃ­do:** AgregaÃ§Ã£o em tempo real  
âœ… **Checkpointing:** TolerÃ¢ncia a falhas  
âœ… **VisualizaÃ§Ã£o DinÃ¢mica:** GrÃ¡ficos atualizados  
âœ… **Pipeline Completo:** Entrada â†’ Processamento â†’ SaÃ­da

## ğŸ“š ReferÃªncias

- [Apache Spark Structured Streaming Guide](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [Spark-Kafka Integration](https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html)
- [kafka-python Documentation](https://kafka-python.readthedocs.io/)
- [WordCloud for Python](https://amueller.github.io/word_cloud/)

---

**Desenvolvido para:** LaboratÃ³rio de Processamento de Dados  
**Data:** Novembro 2025  
**Status:** âœ… Completo e testado
