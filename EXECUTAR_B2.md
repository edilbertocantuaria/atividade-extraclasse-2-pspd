# ğŸš€ Guia de ExecuÃ§Ã£o - B2 (Apache Spark Streaming)

## ğŸ“‹ VisÃ£o Geral

Este guia contÃ©m todas as instruÃ§Ãµes para executar o ambiente B2 (Apache Spark + Kafka + Elasticsearch + Kibana) do zero atÃ© ficar 100% funcional.

**Tecnologias:** Apache Spark 3.4.1, Kafka, Elasticsearch 8.12, Kibana, Zookeeper

---

## ğŸ“¦ PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de ter instalado:

- **Docker** (versÃ£o 20.10 ou superior)
- **Docker Compose** (versÃ£o 2.0 ou superior)
- **Git** (para clonar o repositÃ³rio)
- **curl** (para testes)

### Verificar InstalaÃ§Ãµes

```bash
docker --version
docker compose version
git --version
curl --version
```

---

## ğŸ“ Estrutura do Projeto B2

```
atividade-extraclasse-2-pspd/
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o de containers
â”‚   â”œâ”€â”€ Dockerfile                  # Imagem customizada do Spark
â”‚   â”œâ”€â”€ testar_ambiente.sh          # Script de validaÃ§Ã£o automÃ¡tica
â”‚   â”œâ”€â”€ spark_app/
â”‚   â”‚   â”œâ”€â”€ main.py                 # AplicaÃ§Ã£o Spark Streaming
â”‚   â”‚   â”œâ”€â”€ producer.py             # Produtor de mensagens Kafka
â”‚   â”‚   â”œâ”€â”€ consumer.py             # Consumidor de mensagens Kafka
â”‚   â”‚   â”œâ”€â”€ requirements.txt        # DependÃªncias Python
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ text_source.py      # Gerador de texto aleatÃ³rio
â”‚   â”œâ”€â”€ elastic/
â”‚   â”‚   â”œâ”€â”€ elasticsearch.yml       # ConfiguraÃ§Ã£o Elasticsearch
â”‚   â”‚   â””â”€â”€ kibana.yml              # ConfiguraÃ§Ã£o Kibana
â”‚   â””â”€â”€ notebooks/
â”‚       â””â”€â”€ spark_lab.ipynb         # Jupyter Notebook demonstrativo
â”‚
â””â”€â”€ resultados_spark/
    â”œâ”€â”€ VALIDACAO_B2.md             # Checklist de validaÃ§Ã£o detalhado
    â”œâ”€â”€ testes_kafka.md             # DocumentaÃ§Ã£o testes Kafka
    â”œâ”€â”€ testes_graficos.md          # DocumentaÃ§Ã£o visualizaÃ§Ãµes
    â”œâ”€â”€ erros_resolvidos.md         # Troubleshooting
    â””â”€â”€ relatorio_final_spark.md    # RelatÃ³rio tÃ©cnico completo
```

---

## ğŸš€ Passo a Passo para ExecuÃ§Ã£o

### PASSO 1: Clonar o RepositÃ³rio (se necessÃ¡rio)

```bash
git clone https://github.com/edilbertocantuaria/atividade-extraclasse-2-pspd.git
cd atividade-extraclasse-2-pspd
```

### PASSO 2: Navegar para o DiretÃ³rio Spark

```bash
cd spark
```

### PASSO 3: Subir o Ambiente Completo

```bash
docker compose up -d
```

**Tempo estimado:** 3-5 minutos (primeira execuÃ§Ã£o com download de imagens)

**SaÃ­da esperada:**
```
[+] Running 7/7
 âœ” Network spark_spark-network  Created
 âœ” Container zookeeper          Started
 âœ” Container elasticsearch      Started
 âœ” Container kibana             Started
 âœ” Container kafka              Started
 âœ” Container spark-master       Started
 âœ” Container spark-worker       Started
```

### PASSO 4: Verificar Status dos Containers

```bash
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
```

**Esperado:** 6 containers com status "Up"
- `zookeeper`
- `kafka`
- `elasticsearch`
- `kibana`
- `spark-master`
- `spark-worker`

### PASSO 5: Aguardar InicializaÃ§Ã£o Completa

Aguarde 30-60 segundos para todos os serviÃ§os iniciarem completamente.

**Verificar logs:**
```bash
# Elasticsearch (deve mostrar "GREEN")
docker logs elasticsearch 2>&1 | grep -i "green"

# Kafka (deve mostrar "started")
docker logs kafka 2>&1 | grep -i "started"

# Spark Master
docker logs spark-master 2>&1 | grep -i "started"
```

### PASSO 6: Criar TÃ³pico Kafka

```bash
docker exec -it kafka kafka-topics --create \
  --topic input-topic \
  --bootstrap-server kafka:9092 \
  --replication-factor 1 \
  --partitions 1
```

**SaÃ­da esperada:**
```
Created topic input-topic.
```

**Verificar tÃ³pico criado:**
```bash
docker exec kafka kafka-topics --list --bootstrap-server kafka:9092
```

### PASSO 7: Testar Conectividade

```bash
# Elasticsearch
curl http://localhost:9200
# Deve retornar JSON com informaÃ§Ãµes do cluster

# Kibana
curl http://localhost:5601
# Deve retornar HTML

# Spark Master UI
curl http://localhost:8080
# Deve retornar HTML
```

### PASSO 8: Executar ValidaÃ§Ã£o AutomÃ¡tica

```bash
chmod +x testar_ambiente.sh
./testar_ambiente.sh
```

**SaÃ­da esperada:**
```
âœ… Containers rodando
âœ… Elasticsearch acessÃ­vel
âœ… TÃ³pico input-topic existe
âœ… Producer iniciado
âœ… Consumer recebendo mensagens
âœ… Spark UI acessÃ­vel
âœ… Kibana acessÃ­vel
```

---

## ğŸ§ª Testando o Pipeline Completo

### TESTE 1: Producer (Produtor de Mensagens)

**Iniciar producer em background:**
```bash
docker exec -d spark-master python3 /opt/spark_app/producer.py
```

**Verificar mensagens sendo enviadas:**
```bash
docker logs spark-master 2>&1 | grep "Enviado:"
```

**SaÃ­da esperada:**
```
[1] Enviado: spark kafka bigdata
[2] Enviado: python docker cluster
[3] Enviado: elasticsearch kibana streaming
...
```

### TESTE 2: Consumer (Consumidor de Mensagens)

**Em um novo terminal, rodar consumer:**
```bash
docker exec -it spark-master python3 /opt/spark_app/consumer.py
```

**SaÃ­da esperada:**
```
Consumer iniciado. Aguardando mensagens...
Recebido: spark kafka bigdata
Recebido: python docker cluster
Recebido: elasticsearch kibana streaming
...
```

**Pressione Ctrl+C para parar o consumer**

âœ… **Se chegou atÃ© aqui:** Kafka estÃ¡ funcionando perfeitamente!

### TESTE 3: Spark Streaming (WordCount em Tempo Real)

**Iniciar aplicaÃ§Ã£o Spark Streaming:**
```bash
docker exec -it spark-master spark-submit \
  --packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.4.1 \
  /opt/spark_app/main.py
```

**SaÃ­da esperada (a cada 5 segundos):**
```
-------------------------------------------
Time: 2025-11-10 01:45:00
-------------------------------------------
(spark, 15)
(kafka, 12)
(python, 10)
(bigdata, 8)
...
Enviado ao ES: spark -> 15
Enviado ao ES: kafka -> 12
```

âœ… **Se aparecer essa saÃ­da:** Spark Streaming estÃ¡ processando!

**Deixe rodando por 2-3 minutos para acumular dados**

### TESTE 4: Verificar Dados no Elasticsearch

**Em outro terminal:**
```bash
# Listar Ã­ndices
curl http://localhost:9200/_cat/indices?v

# Buscar dados do Ã­ndice wordcount
curl "http://localhost:9200/wordcount/_search?pretty&size=20"
```

**SaÃ­da esperada:**
```json
{
  "hits": {
    "total": { "value": 150 },
    "hits": [
      {
        "_source": {
          "word": "spark",
          "count": 15
        }
      },
      {
        "_source": {
          "word": "kafka",
          "count": 12
        }
      }
    ]
  }
}
```

âœ… **Se retornar dados:** Elasticsearch estÃ¡ recebendo!

### TESTE 5: Visualizar no Kibana

**1. Acessar Kibana:**
```
http://localhost:5601
```

**2. Criar Data View:**
- Clicar em â˜° (menu hamburger) â†’ Stack Management
- Data Views â†’ Create data view
- **Name:** `wordcount*`
- **Index pattern:** `wordcount*`
- **Timestamp field:** Selecionar "I don't want to use the time filter"
- Click "Save data view to Kibana"

**3. Visualizar Dados:**
- â˜° â†’ Analytics â†’ Discover
- Selecionar data view `wordcount*`
- VocÃª deve ver a lista de palavras e contagens

**4. Criar VisualizaÃ§Ã£o (Word Cloud):**
- â˜° â†’ Analytics â†’ Visualize Library
- Create visualization â†’ Lens
- Drag & drop:
  - **Vertical axis:** `count` (Sum)
  - **Horizontal axis:** `word.keyword` (Top 20)
- Escolher tipo de grÃ¡fico: Bar chart ou Table
- Save: "WordCount Real-Time"

**5. Criar Dashboard:**
- â˜° â†’ Analytics â†’ Dashboard
- Create dashboard
- Add from library â†’ Selecionar "WordCount Real-Time"
- Configurar auto-refresh: (Ã­cone de relÃ³gio) â†’ 10 seconds
- Save dashboard: "Spark Streaming Dashboard"

âœ… **Dashboard atualiza a cada 10 segundos automaticamente!**

---

## ğŸŒ Portas e Acessos

| ServiÃ§o | URL | DescriÃ§Ã£o |
|---------|-----|-----------|
| **Spark Master UI** | http://localhost:8080 | Interface do Spark (jobs, workers) |
| **Kibana** | http://localhost:5601 | Dashboard e visualizaÃ§Ãµes |
| **Elasticsearch** | http://localhost:9200 | API REST do Elasticsearch |
| **Kafka** | localhost:9092 | Broker Kafka (interno) |
| **Zookeeper** | localhost:2181 | CoordenaÃ§Ã£o Kafka (interno) |

---

## âœ… Checklist de ValidaÃ§Ã£o Completa

Use este checklist para garantir que tudo estÃ¡ funcionando:

- [ ] 6 containers rodando (`docker ps`)
- [ ] Elasticsearch retorna JSON em http://localhost:9200
- [ ] Kibana acessÃ­vel em http://localhost:5601
- [ ] Spark UI acessÃ­vel em http://localhost:8080
- [ ] TÃ³pico `input-topic` criado no Kafka
- [ ] Producer enviando mensagens
- [ ] Consumer recebendo mensagens
- [ ] Spark Streaming imprimindo WordCount a cada 5s
- [ ] Elasticsearch contÃ©m Ã­ndice `wordcount` com dados
- [ ] Kibana exibe dados do Ã­ndice `wordcount`
- [ ] Dashboard Kibana atualiza automaticamente

**Se todos marcados:** ğŸ‰ **B2 estÃ¡ 100% funcional!**

---

## ğŸ›‘ Parar e Limpar o Ambiente

### Parar Containers (mantÃ©m dados)
```bash
docker compose stop
```

### Parar e Remover Containers
```bash
docker compose down
```

### Limpar Completamente (incluindo volumes)
```bash
docker compose down -v
docker system prune -f
```

### Reiniciar do Zero
```bash
docker compose down -v
docker compose up -d
# Repetir PASSO 6 em diante
```

---

## ğŸ› Troubleshooting (ResoluÃ§Ã£o de Problemas)

### Problema 1: Container nÃ£o sobe

**Sintoma:** `docker compose up -d` falha

**SoluÃ§Ã£o:**
```bash
# Ver logs de erro
docker compose logs

# Reconstruir imagens
docker compose build --no-cache
docker compose up -d
```

### Problema 2: Porta jÃ¡ em uso

**Sintoma:** `Error: port is already allocated`

**SoluÃ§Ã£o:**
```bash
# Identificar processo usando a porta
sudo lsof -i :9200  # Substituir pelo nÃºmero da porta

# Matar processo
sudo kill -9 <PID>

# Ou alterar porta no docker-compose.yml
```

### Problema 3: Elasticsearch nÃ£o inicia (memÃ³ria)

**Sintoma:** Elasticsearch morre constantemente

**SoluÃ§Ã£o:**
```bash
# Aumentar memÃ³ria no docker-compose.yml
# Alterar de -Xms1g -Xmx1g para -Xms2g -Xmx2g
```

### Problema 4: Kafka nÃ£o conecta

**Sintoma:** Producer ou Consumer nÃ£o conseguem conectar

**SoluÃ§Ã£o:**
```bash
# Verificar se tÃ³pico existe
docker exec kafka kafka-topics --list --bootstrap-server kafka:9092

# Recriar tÃ³pico
docker exec kafka kafka-topics --delete --topic input-topic --bootstrap-server kafka:9092
docker exec kafka kafka-topics --create --topic input-topic --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1
```

### Problema 5: Spark nÃ£o processa mensagens

**Sintoma:** Spark inicia mas nÃ£o mostra WordCount

**SoluÃ§Ã£o:**
```bash
# Verificar se producer estÃ¡ rodando
docker logs spark-master 2>&1 | grep "Enviado"

# Reiniciar producer
docker exec -d spark-master python3 /opt/spark_app/producer.py

# Verificar logs do Spark
docker logs spark-master
```

### Problema 6: Kibana nÃ£o mostra dados

**Sintoma:** Data view vazio

**SoluÃ§Ã£o:**
```bash
# Verificar se dados estÃ£o no Elasticsearch
curl "http://localhost:9200/wordcount/_count"

# Se retornar count: 0, reiniciar Spark Streaming
# Se retornar count > 0, recriar data view no Kibana
```

### Problema 7: PermissÃµes negadas

**Sintoma:** `Permission denied`

**SoluÃ§Ã£o:**
```bash
# Dar permissÃ£o ao script
chmod +x testar_ambiente.sh

# Ou rodar com sudo
sudo docker compose up -d
```

---

## ğŸ“Š Comandos Ãšteis

### Logs em Tempo Real
```bash
# Todos os containers
docker compose logs -f

# Container especÃ­fico
docker logs -f spark-master
docker logs -f kafka
docker logs -f elasticsearch
```

### Entrar em um Container
```bash
docker exec -it spark-master bash
docker exec -it kafka bash
```

### Verificar Recursos
```bash
# CPU e memÃ³ria dos containers
docker stats

# EspaÃ§o em disco
docker system df
```

### Limpar Dados do Elasticsearch
```bash
# Deletar Ã­ndice wordcount
curl -X DELETE "http://localhost:9200/wordcount"

# Recriar do zero
# (Spark vai recriar automaticamente quando processar dados)
```

---

## ğŸ“š Arquivos de DocumentaÃ§Ã£o

Para mais detalhes tÃ©cnicos, consulte:

- **`resultados_spark/VALIDACAO_B2.md`** - Guia detalhado de validaÃ§Ã£o passo a passo
- **`resultados_spark/testes_kafka.md`** - DocumentaÃ§Ã£o completa dos testes Kafka
- **`resultados_spark/testes_graficos.md`** - Como criar visualizaÃ§Ãµes no Kibana
- **`resultados_spark/erros_resolvidos.md`** - Erros comuns e suas soluÃ§Ãµes
- **`resultados_spark/relatorio_final_spark.md`** - RelatÃ³rio tÃ©cnico completo

---

## ğŸ“ Entendendo o Fluxo de Dados

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Producer   â”‚  1. Gera frases aleatÃ³rias com palavras tÃ©cnicas
â”‚  (Python)   â”‚  2. Envia para tÃ³pico Kafka "input-topic"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka     â”‚  3. Armazena mensagens em fila
â”‚  (Broker)   â”‚  4. Distribui para consumidores
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Spark     â”‚  5. Consome mensagens a cada 5 segundos (micro-batch)
â”‚  Streaming  â”‚  6. Faz WordCount (conta palavras)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  7. Agrega contagens
       â”‚
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Elasticsearchâ”‚  8. Armazena resultados no Ã­ndice "wordcount"
â”‚   (Index)   â”‚  9. Indexa para busca rÃ¡pida
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kibana    â”‚  10. Visualiza dados em dashboard
â”‚ (Dashboard) â”‚  11. Atualiza automaticamente a cada 10s
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Objetivos de Aprendizado

Ao executar este projeto, vocÃª aprende:

- âœ… OrquestraÃ§Ã£o multi-container com Docker Compose
- âœ… Mensageria com Apache Kafka
- âœ… Processamento de streaming com Apache Spark
- âœ… Armazenamento e busca com Elasticsearch
- âœ… VisualizaÃ§Ã£o de dados com Kibana
- âœ… IntegraÃ§Ã£o de componentes Big Data
- âœ… Troubleshooting de sistemas distribuÃ­dos

---

## ğŸ“ Notas Importantes

1. **Primeira execuÃ§Ã£o Ã© mais lenta** devido ao download das imagens Docker (~2-3 GB)
2. **Requer ~4-6 GB de RAM** disponÃ­vel para rodar todos os containers
3. **Producer roda indefinidamente** atÃ© ser parado manualmente
4. **Dados sÃ£o perdidos** ao fazer `docker compose down -v`
5. **Kibana demora ~1 minuto** para inicializar completamente
6. **Elasticsearch requer vm.max_map_count configurado** em alguns sistemas Linux:
   ```bash
   sudo sysctl -w vm.max_map_count=262144
   ```

---

## âœ¨ CrÃ©ditos

**Disciplina:** ProgramaÃ§Ã£o para Sistemas Paralelos e DistribuÃ­dos (PSPD)  
**InstituiÃ§Ã£o:** Universidade de BrasÃ­lia (UnB)  
**Data:** Novembro 2025  

---

## ğŸ“§ Suporte

Para dÃºvidas ou problemas:

1. Consulte a seÃ§Ã£o **Troubleshooting** acima
2. Verifique os logs: `docker compose logs`
3. Consulte `resultados_spark/erros_resolvidos.md`
4. Abra uma issue no repositÃ³rio GitHub

---

**ğŸš€ Bom aprendizado!**
