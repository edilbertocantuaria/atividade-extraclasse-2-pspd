# Como Executar o Projeto - Atividade Extraclasse 2

> **Guia completo e objetivo** para executar do zero as implementaÃ§Ãµes B1 (Hadoop) e B2 (Spark Streaming) + extensÃ£o ML (anÃ¡lise de sentimentos)

---

## ðŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [PrÃ©-requisitos](#prÃ©-requisitos)
- [B1: Apache Hadoop - WordCount DistribuÃ­do](#b1-apache-hadoop---wordcount-distribuÃ­do)
- [B2: Apache Spark Streaming - Processamento em Tempo Real](#b2-apache-spark-streaming---processamento-em-tempo-real)
- [ExtensÃ£o ML: AnÃ¡lise de Sentimentos (Opcional)](#extensÃ£o-ml-anÃ¡lise-de-sentimentos-opcional)
- [Troubleshooting](#troubleshooting)
- [Estrutura de Resultados](#estrutura-de-resultados)

---

## VisÃ£o Geral

Este projeto implementa **processamento distribuÃ­do de dados** utilizando dois frameworks Apache:

### **B1 - Hadoop MapReduce**
- WordCount em cluster distribuÃ­do (1 master + 2 workers)
- 5 configuraÃ§Ãµes diferentes testadas
- Testes de tolerÃ¢ncia a falhas e concorrÃªncia
- Dataset massivo (500MB+) para execuÃ§Ã£o realÃ­stica (3-4 minutos)

### **B2 - Spark Streaming**
- Pipeline de streaming em tempo real com Kafka
- Processamento de mensagens sociais simuladas
- IndexaÃ§Ã£o em Elasticsearch
- Dashboard Kibana para visualizaÃ§Ã£o

### **ExtensÃ£o ML (Opcional)**
- AnÃ¡lise de sentimentos com VADER
- ClassificaÃ§Ã£o automÃ¡tica (positivo/negativo/neutro)
- MÃ©tricas de polaridade e subjetividade

---

## PrÃ©-requisitos

### Hardware MÃ­nimo
- **RAM**: 8GB (recomendado: 16GB)
- **Disco**: 20GB livres
- **CPU**: 4 cores (recomendado: 8 cores)

### Software NecessÃ¡rio
```bash
# Verificar Docker
docker --version  # VersÃ£o 20.10+
docker-compose --version  # VersÃ£o 1.29+

# Verificar Python
python3 --version  # Python 3.8+

# Verificar portas disponÃ­veis
# Hadoop: 8088, 9870, 9000
# Spark: 8080, 4040, 7077
# Kafka: 9092, 2181
# Elasticsearch: 9200
# Kibana: 5601
netstat -tuln | grep -E '8088|9870|8080|9092|9200|5601'
# Se algo aparecer, essas portas jÃ¡ estÃ£o em uso
```

### Clonar/Acessar Projeto
```bash
cd /home/edilberto/pspd/atividade-extraclasse-2-pspd
```

---

## B1: Apache Hadoop - WordCount DistribuÃ­do

### ðŸŽ¯ Objetivo
Executar algoritmo WordCount em cluster Hadoop com diferentes configuraÃ§Ãµes para anÃ¡lise comparativa de desempenho.

### ðŸ“ Passo a Passo

#### **1. Iniciar Cluster Hadoop (3 nÃ³s)**
```bash
cd /home/edilberto/pspd/atividade-extraclasse-2-pspd/hadoop
docker-compose up -d
sleep 10  # Aguardar containers iniciarem
```

**Iniciar serviÃ§os Hadoop:**
```bash
docker exec hadoop-master bash -c "su - hadoop -c '/home/hadoop/hadoop/sbin/start-all.sh'"
sleep 30  # Aguardar serviÃ§os HDFS + YARN iniciarem
```

**Verificar status:**
```bash
# Verificar containers
docker ps --filter "name=hadoop-"
# Deve mostrar 3 containers UP: hadoop-master, hadoop-worker1, hadoop-worker2

# Verificar processos Java (deve mostrar 3 ou mais)
docker exec hadoop-master bash -c "ps aux | grep java | grep -v grep | wc -l"
```

**Interfaces web disponÃ­veis:**
- **YARN ResourceManager**: http://localhost:8088
- **HDFS NameNode**: http://localhost:9870

> âœ… **Testar acesso:** Abra as URLs no navegador. VocÃª deve ver as interfaces do Hadoop.

#### **2. Gerar Dataset Massivo**
```bash
cd /home/edilberto/pspd/atividade-extraclasse-2-pspd
./scripts/generate_large_dataset.sh 500
# Gera 500MB de dados textuais (ajustar se necessÃ¡rio)
```

**Verificar upload no HDFS:**
```bash
docker exec hadoop-master hdfs dfs -ls -h /user/hadoop/input
# Deve mostrar ~500MB em 10 arquivos
```

#### **3. Executar Todos os Testes Automaticamente**
```bash
./scripts/run_all_tests.sh
```

â±ï¸ **DuraÃ§Ã£o estimada:** 30-40 minutos

**O que esse script faz:**
- Teste baseline (configuraÃ§Ã£o padrÃ£o)
- Teste 1: AlteraÃ§Ã£o de memÃ³ria YARN
- Teste 2: AlteraÃ§Ã£o de replicaÃ§Ã£o HDFS
- Teste 3: AlteraÃ§Ã£o de block size
- Teste 4: AlteraÃ§Ã£o de nÃºmero de reducers
- Teste 5: AlteraÃ§Ã£o de speculative execution
- Coleta de mÃ©tricas padronizadas
- GeraÃ§Ã£o de relatÃ³rio consolidado

#### **4. (Opcional) Testes AvanÃ§ados**

**Teste de TolerÃ¢ncia a Falhas:**
```bash
./scripts/test_fault_tolerance.sh
# Testa comportamento ao remover/adicionar workers durante execuÃ§Ã£o
# DuraÃ§Ã£o: ~15-20 minutos por cenÃ¡rio (4 cenÃ¡rios = 60-80 minutos total)
```

> â±ï¸ **Importante**: Este teste Ã© **longo** e executa 4 cenÃ¡rios sequencialmente:
> - CenÃ¡rio 1 (Baseline): ~15-20 min
> - CenÃ¡rio 2 (Falha 1 worker): ~20-30 min (mais lento devido Ã  reduÃ§Ã£o de recursos)
> - CenÃ¡rio 3 (Falha 2 workers): ~30-40 min (muito mais lento)
> - CenÃ¡rio 4 (AdiÃ§Ã£o de worker): ~15-20 min
>
> **Monitorar progresso** em outro terminal:
> ```bash
> # Ver jobs em execuÃ§Ã£o
> watch -n 5 'docker exec hadoop-master yarn application -list -appStates RUNNING'
> 
> # Ver progresso do job atual (substitua APPLICATION_ID)
> watch -n 10 'docker exec hadoop-master yarn application -status APPLICATION_ID | grep Progress'
> ```

**Teste de ConcorrÃªncia:**
```bash
./scripts/test_concurrency.sh
# Testa 2, 3 e 4 jobs simultÃ¢neos
# DuraÃ§Ã£o: ~10-15 minutos total
```

> â±ï¸ **Importante**: Executa 3 testes em sequÃªncia:
> - Teste 1: 2 jobs simultÃ¢neos (~3-5 min)
> - Teste 2: 3 jobs simultÃ¢neos (~4-6 min)
> - Teste 3: 4 jobs simultÃ¢neos (~5-8 min)
>
> **Monitorar jobs simultÃ¢neos**:
> ```bash
> watch -n 5 'docker exec hadoop-master yarn application -list -appStates RUNNING'
> ```

#### **5. Analisar Resultados**
```bash
# Ver relatÃ³rio final consolidado
cat resultados/B1/RELATORIO_FINAL_COMPLETO.md

# Ver todos os tempos de execuÃ§Ã£o
for dir in resultados/B1/teste*/; do
  test_name=$(basename "$dir")
  duration=$(cat "$dir/time_stats.txt" 2>/dev/null || echo "N/A")
  echo "$test_name: ${duration}s"
done
```

#### **6. Parar Cluster**
```bash
# Parar serviÃ§os Hadoop
docker exec hadoop-master bash -c "su - hadoop -c '/home/hadoop/hadoop/sbin/stop-all.sh'"

# Parar containers
cd /home/edilberto/pspd/atividade-extraclasse-2-pspd/hadoop
docker-compose down
```

### âœ… Checklist B1

- [ ] Cluster Hadoop iniciado (3 containers ativos)
- [ ] Dataset massivo gerado (500MB+)
- [ ] 5 configuraÃ§Ãµes diferentes testadas
- [ ] MÃ©tricas coletadas (tempo, throughput, variaÃ§Ã£o %)
- [ ] Testes de falhas executados (opcional)
- [ ] Testes de concorrÃªncia executados (opcional)
- [ ] RelatÃ³rio final gerado
- [ ] Screenshots das interfaces web (YARN, HDFS)

---

## B2: Apache Spark Streaming - Processamento em Tempo Real

### ðŸŽ¯ Objetivo
Implementar pipeline de streaming que processa mensagens de rede social simulada, realiza contagem de palavras em janelas deslizantes e indexa resultados em Elasticsearch para visualizaÃ§Ã£o em Kibana.

### ðŸ“ Passo a Passo

#### **1. Iniciar Infraestrutura Docker**
```bash
cd /home/edilberto/pspd/atividade-extraclasse-2-pspd/spark
docker-compose up -d
sleep 30  # Aguardar serviÃ§os iniciarem
```

**Verificar serviÃ§os:**
```bash
docker-compose ps
# Deve mostrar 6 containers ATIVOS:
# - zookeeper
# - kafka
# - spark-master
# - spark-worker
# - elasticsearch
# - kibana
```

**Interfaces web disponÃ­veis:**
- **Spark Master**: http://localhost:8080
- **Elasticsearch**: http://localhost:9200
- **Kibana**: http://localhost:5601

> âš ï¸ **Nota**: Elasticsearch pode levar atÃ© 2 minutos para iniciar, e Kibana atÃ© 3 minutos. Aguarde antes de acessar.

#### **2. Abrir Notebook Jupyter**
```bash
# No VS Code, abrir arquivo:
spark/notebooks/B2_SPARK_STREAMING_COMPLETO.ipynb
```

**Selecionar kernel Python:**
- Clicar em "Select Kernel" (canto superior direito)
- Escolher Python 3.8+ do sistema

#### **3. Executar CÃ©lulas do Notebook Sequencialmente**

**IMPORTANTE:** Executar cÃ©lulas na ordem 1 â†’ 50 (nÃ£o pular nenhuma)

**SeÃ§Ãµes principais:**

**SeÃ§Ã£o 1 - Justificativa Discord (cÃ©lulas 1-2)**
- ExplicaÃ§Ã£o sobre nÃ£o uso do Discord API (substituÃ­do por simulaÃ§Ã£o)
- Executar cÃ©lulas 1 e 2

**SeÃ§Ã£o 2 - Setup Kafka (cÃ©lulas 3-9)**
- Instalar dependÃªncias Python (`kafka-python`, `elasticsearch`)
- Criar tÃ³picos Kafka (`social-input`, `wordcount-output`)
- Executar cÃ©lulas 3 a 9
- â±ï¸ ~2 minutos

**SeÃ§Ã£o 3 - Producer Kafka (cÃ©lulas 10-18)**
- Configurar producer de mensagens
- Gerar dados sintÃ©ticos (mensagens sociais simuladas)
- Testar envio
- Executar cÃ©lulas 10 a 18
- â±ï¸ ~2 minutos

**SeÃ§Ã£o 4 - Pipeline Spark Streaming (cÃ©lulas 19-35)**
- Configurar SparkSession
- Conectar ao Kafka
- Implementar transformaÃ§Ãµes (split, contagem)
- Aplicar windowing (30s tumbling)
- Escrever resultados de volta ao Kafka
- Executar cÃ©lulas 19 a 35
- â±ï¸ ~3 minutos

**SeÃ§Ã£o 5 - ExecuÃ§Ã£o Background (cÃ©lulas 36-39)**
- Iniciar producer em background (3 minutos, 3 msgs/seg)
- Iniciar streaming queries
- Executar cÃ©lulas 36 a 39
- â±ï¸ ~1 minuto (setup), depois continua rodando

**SeÃ§Ã£o 6 - Consumer Elasticsearch (cÃ©lulas 40-45)**
- Criar Ã­ndice Elasticsearch
- Configurar consumer que lÃª do Kafka
- Indexar documentos no ES
- Executar cÃ©lulas 40 a 45
- â±ï¸ ~2 minutos

**SeÃ§Ã£o 7 - Dashboard Kibana (cÃ©lulas 46-48)**
- Acessar Kibana: http://localhost:5601
- Criar data view `wordcount-realtime`
- Criar visualizaÃ§Ã£o Tag Cloud
- Criar dashboard
- Executar cÃ©lulas 46 a 48 (instruÃ§Ãµes detalhadas)
- â±ï¸ ~5 minutos

**SeÃ§Ã£o 8 - FinalizaÃ§Ã£o (cÃ©lulas 49-50)**
- Parar streaming queries
- Ver estatÃ­sticas finais
- Cleanup
- Executar cÃ©lulas 49 a 50
- â±ï¸ ~1 minuto

#### **4. Criar Dashboard Kibana**

**Acessar Kibana:**
```
http://localhost:5601
```

**Criar Data View:**
1. Menu â†’ Stack Management â†’ Data Views
2. Clicar "Create data view"
3. Name: `wordcount-realtime`
4. Index pattern: `wordcount-realtime`
5. Timestamp field: `timestamp`
6. Save

**Criar VisualizaÃ§Ã£o Tag Cloud:**
1. Menu â†’ Visualize Library â†’ Create visualization
2. Tipo: "Tag cloud"
3. Data view: `wordcount-realtime`
4. Configurar:
   - Bucket: Tags
   - Aggregation: Terms
   - Field: `word.keyword`
   - Size: 50
   - Order by: Metric (Count)
5. Metrics: Count
6. Save: "WordCount Tag Cloud"

**Criar Dashboard:**
1. Menu â†’ Dashboard â†’ Create dashboard
2. Add visualization: "WordCount Tag Cloud"
3. Ajustar tamanho
4. Configurar auto-refresh: 10s (canto superior direito)
5. Save dashboard: "Real-time WordCount"

#### **5. Capturar Screenshots**

Salvar em `resultados_spark/`:
- `kibana_dashboard_wordcloud.png` - Dashboard completo
- `kibana_tagcloud_detail.png` - Tag Cloud em detalhe
- `spark_webui_streaming.png` - Spark Master mostrando queries ativas

#### **6. Parar Infraestrutura**
```bash
cd /home/edilberto/pspd/atividade-extraclasse-2-pspd/spark
docker-compose down
```

### âœ… Checklist B2

- [ ] Infraestrutura Docker iniciada (6 containers ativos)
- [ ] Notebook executado cÃ©lula por cÃ©lula (1 â†’ 50)
- [ ] TÃ³picos Kafka criados (`social-input`, `wordcount-output`)
- [ ] Producer enviou ~540 mensagens (3 msgs/seg Ã— 180s)
- [ ] Spark queries processaram janelas de 30s
- [ ] Consumer indexou documentos no Elasticsearch
- [ ] Data view criado no Kibana
- [ ] Dashboard com Tag Cloud funcionando
- [ ] Auto-refresh configurado (10s)
- [ ] Screenshots capturados
- [ ] Justificativa Discord documentada

---

## ExtensÃ£o ML: AnÃ¡lise de Sentimentos (Opcional)

### ðŸŽ¯ Objetivo
Adicionar camada de Machine Learning ao pipeline B2 para classificar sentimentos das mensagens (positivo/negativo/neutro).

### ðŸ“ Passo a Passo

#### **1. PrÃ©-requisitos**
- Infraestrutura B2 em execuÃ§Ã£o
- Notebook `B2_SPARK_STREAMING_COMPLETO.ipynb` executado atÃ© cÃ©lula 50

#### **2. Executar SeÃ§Ã£o 8.4 - ExtensÃ£o ML (cÃ©lulas 51-65)**

**CÃ©lulas 51-55: InstalaÃ§Ã£o e Import**
- Instalar `vaderSentiment`
- Importar bibliotecas necessÃ¡rias
- â±ï¸ ~1 minuto

**CÃ©lulas 56-58: AnÃ¡lise de Sentimentos**
- Configurar VADER analyzer
- Aplicar anÃ¡lise Ã s mensagens
- Calcular scores (positivo, negativo, neutro, composto)
- â±ï¸ ~2 minutos

**CÃ©lulas 59-61: ClassificaÃ§Ã£o**
- Categorizar mensagens baseado em score composto:
  - `>= 0.05`: Positivo
  - `<= -0.05`: Negativo
  - `-0.05 a 0.05`: Neutro
- â±ï¸ ~1 minuto

**CÃ©lulas 62-64: IndexaÃ§Ã£o e VisualizaÃ§Ã£o**
- Indexar dados enriquecidos no Elasticsearch (Ã­ndice `wordcount-sentiments`)
- Criar visualizaÃ§Ãµes no Kibana:
  - Pie chart: DistribuiÃ§Ã£o de sentimentos
  - Bar chart: Top palavras por sentimento
  - Line chart: EvoluÃ§Ã£o temporal de sentimentos
- â±ï¸ ~5 minutos

**CÃ©lula 65: EstatÃ­sticas Finais**
- Ver mÃ©tricas agregadas
- Validar classificaÃ§Ã£o
- â±ï¸ ~1 minuto

#### **3. Criar VisualizaÃ§Ãµes no Kibana**

**Criar Data View para Sentimentos:**
1. Stack Management â†’ Data Views â†’ Create
2. Name: `wordcount-sentiments`
3. Index pattern: `wordcount-sentiments`
4. Timestamp: `timestamp`
5. Save

**VisualizaÃ§Ã£o 1 - Pie Chart (DistribuiÃ§Ã£o):**
1. Visualize â†’ Create â†’ Pie
2. Data view: `wordcount-sentiments`
3. Slice by: Terms â†’ `sentiment.keyword`
4. Save: "Sentiment Distribution"

**VisualizaÃ§Ã£o 2 - Bar Chart (Top Palavras):**
1. Visualize â†’ Create â†’ Bar vertical
2. X-axis: Terms â†’ `word.keyword` (top 10)
3. Split series: Terms â†’ `sentiment.keyword`
4. Save: "Top Words by Sentiment"

**VisualizaÃ§Ã£o 3 - Line Chart (Timeline):**
1. Visualize â†’ Create â†’ Line
2. X-axis: Date Histogram â†’ `timestamp`
3. Y-axis: Count
4. Split series: Terms â†’ `sentiment.keyword`
5. Save: "Sentiment Timeline"

**Dashboard ML:**
1. Dashboard â†’ Create
2. Adicionar 3 visualizaÃ§Ãµes criadas
3. Save: "Sentiment Analysis Dashboard"

#### **4. Capturar Screenshots**

Salvar em `resultados_spark/`:
- `kibana_sentiment_pie.png`
- `kibana_sentiment_bars.png`
- `kibana_sentiment_timeline.png`
- `kibana_dashboard_ml.png`

### âœ… Checklist ML

- [ ] VADER instalado e configurado
- [ ] Scores de sentimento calculados (pos, neg, neu, compound)
- [ ] ClassificaÃ§Ã£o aplicada (positivo/negativo/neutro)
- [ ] Dados indexados no Elasticsearch (`wordcount-sentiments`)
- [ ] 3 visualizaÃ§Ãµes criadas no Kibana
- [ ] Dashboard ML completo
- [ ] Screenshots capturados
- [ ] ReferÃªncias acadÃªmicas citadas (VADER paper)

---

## Troubleshooting

### Problemas Comuns B1 (Hadoop)

#### Cluster nÃ£o inicia ou interfaces web nÃ£o respondem
```bash
# 1. Verificar se containers estÃ£o rodando
docker ps --filter "name=hadoop-"

# 2. Verificar se processos Java estÃ£o ativos
docker exec hadoop-master bash -c "ps aux | grep java | grep -v grep"

# 3. Se nÃ£o houver processos Java, iniciar serviÃ§os manualmente
docker exec hadoop-master bash -c "su - hadoop -c '/home/hadoop/hadoop/sbin/start-all.sh'"
sleep 30

# 4. Verificar logs se ainda houver problema
docker logs hadoop-master --tail 100
docker logs hadoop-worker1 --tail 50

# 5. Reiniciar completo (Ãºltima opÃ§Ã£o)
cd hadoop
docker exec hadoop-master bash -c "su - hadoop -c '/home/hadoop/hadoop/sbin/stop-all.sh'"
docker-compose down -v
docker-compose up -d
sleep 10
docker exec hadoop-master bash -c "su - hadoop -c '/home/hadoop/hadoop/sbin/start-all.sh'"
sleep 30

# 6. Testar acesso Ã s interfaces
curl -I http://localhost:8088 2>/dev/null | head -1  # YARN
curl -I http://localhost:9870 2>/dev/null | head -1  # HDFS
```

#### Job muito rÃ¡pido (< 3 minutos)
```bash
# Gerar dataset maior
./scripts/generate_large_dataset.sh 1000  # 1GB
# ou
./scripts/generate_large_dataset.sh 2000  # 2GB
```

#### Workers nÃ£o conectam
```bash
# Ver nÃ³s ativos no YARN
docker exec hadoop-master yarn node -list

# Verificar se DataNodes estÃ£o registrados
docker exec hadoop-master hdfs dfsadmin -report

# Reiniciar workers
docker restart hadoop-worker1 hadoop-worker2
sleep 30
```

#### Sem espaÃ§o em disco
```bash
# Limpar outputs antigos
docker exec hadoop-master hdfs dfs -rm -r -f /user/hadoop/output/*

# Limpar Docker
docker system prune -a
```

### Problemas Comuns B2 (Spark)

#### Container nÃ£o inicia
```bash
# Ver logs especÃ­ficos
docker logs kafka --tail 100
docker logs elasticsearch --tail 100
docker logs spark-master --tail 100

# Reiniciar serviÃ§o especÃ­fico
cd spark
docker-compose restart <service-name>
```

#### Elasticsearch nÃ£o aceita conexÃµes
```bash
# Verificar saÃºde
curl http://localhost:9200/_cluster/health?pretty

# Aguardar inicializaÃ§Ã£o (pode levar 2 minutos)
watch -n 5 'curl -s http://localhost:9200 | grep cluster_name'
```

#### Kafka nÃ£o recebe mensagens
```bash
# Verificar broker
docker exec kafka kafka-broker-api-versions --bootstrap-server localhost:9092

# Verificar tÃ³picos
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Ver mensagens no tÃ³pico
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic social-input \
  --from-beginning \
  --max-messages 10
```

#### Spark query nÃ£o processa
```bash
# Verificar Spark Web UI
firefox http://localhost:8080

# Verificar no notebook se query estÃ¡ ativa
print(query_kafka.isActive)
print(query_kafka.status)

# Ver logs do worker
docker logs spark-worker --tail 100
```

#### Kibana nÃ£o carrega
```bash
# Verificar conexÃ£o com Elasticsearch
docker exec kibana curl http://elasticsearch:9200

# Aguardar mais tempo (pode levar 3 minutos apÃ³s ES)
docker logs kibana --tail 100
```

#### Erro ao instalar pacotes Python
```bash
# No notebook, instalar manualmente
!pip install kafka-python elasticsearch vaderSentiment

# Verificar instalaÃ§Ã£o
!pip list | grep -E 'kafka|elastic|vader'
```

### Problemas Comuns ML

#### VADER nÃ£o instala
```bash
# No notebook
!pip install --upgrade pip
!pip install vaderSentiment

# Verificar
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
```

#### Scores sempre neutros
```bash
# Verificar idioma das mensagens (VADER Ã© otimizado para inglÃªs)
# Garantir que mensagens tÃªm palavras com carga emocional
# Ver exemplos na cÃ©lula 56 do notebook
```

---

## Estrutura de Resultados

```
atividade-extraclasse-2-pspd/
â”œâ”€â”€ resultados/B1/                          # Resultados Hadoop
â”‚   â”œâ”€â”€ RELATORIO_FINAL_COMPLETO.md         # RelatÃ³rio consolidado B1
â”‚   â”œâ”€â”€ teste0_baseline/                    # ConfiguraÃ§Ã£o padrÃ£o
â”‚   â”‚   â”œâ”€â”€ job_output.txt
â”‚   â”‚   â”œâ”€â”€ time_stats.txt
â”‚   â”‚   â”œâ”€â”€ metrics_summary.csv
â”‚   â”‚   â””â”€â”€ throughput_metrics.txt
â”‚   â”œâ”€â”€ teste1_memoria/                     # Teste memÃ³ria
â”‚   â”œâ”€â”€ teste2_replicacao/                  # Teste replicaÃ§Ã£o
â”‚   â”œâ”€â”€ teste3_blocksize/                   # Teste block size
â”‚   â”œâ”€â”€ teste4_reducers/                    # Teste reducers
â”‚   â”œâ”€â”€ teste5_speculative/                 # Teste speculative execution
â”‚   â”œâ”€â”€ teste_tolerancia_falhas/            # Testes de falhas
â”‚   â”‚   â””â”€â”€ run_TIMESTAMP/
â”‚   â”‚       â””â”€â”€ relatorio_tolerancia_falhas.md
â”‚   â””â”€â”€ teste_concorrencia/                 # Testes de concorrÃªncia
â”‚       â””â”€â”€ run_TIMESTAMP/
â”‚           â””â”€â”€ relatorio_concorrencia.md
â”‚
â”œâ”€â”€ resultados_spark/                       # Resultados Spark
â”‚   â”œâ”€â”€ IMPLEMENTACAO_B2_COMPLETA.md        # DocumentaÃ§Ã£o detalhada B2
â”‚   â”œâ”€â”€ VALIDACAO_B2_DETALHADA.md           # Checklist de validaÃ§Ã£o
â”‚   â”œâ”€â”€ EXTENSAO_ML_SENTIMENTOS.md          # DocumentaÃ§Ã£o ML
â”‚   â”œâ”€â”€ kibana_dashboard_wordcloud.png      # Screenshots
â”‚   â”œâ”€â”€ kibana_tagcloud_detail.png
â”‚   â”œâ”€â”€ kibana_sentiment_pie.png
â”‚   â””â”€â”€ kibana_dashboard_ml.png
â”‚
â””â”€â”€ spark/notebooks/
    â””â”€â”€ B2_SPARK_STREAMING_COMPLETO.ipynb   # Notebook completo (65 cÃ©lulas)
```

---

## ReferÃªncias

### B1 - Hadoop
- [Apache Hadoop Documentation](https://hadoop.apache.org/docs/current/)
- [YARN Architecture](https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)
- [HDFS Design](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)

### B2 - Spark
- [Spark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [Spark-Kafka Integration](https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html)
- [Elasticsearch Python Client](https://elasticsearch-py.readthedocs.io/)

### ML
- **VADER**: Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. *Eighth International Conference on Weblogs and Social Media (ICWSM-14)*.
- [VADER GitHub](https://github.com/cjhutto/vaderSentiment)

---

## ðŸ“ž Suporte

Para dÃºvidas ou problemas:

1. Consultar seÃ§Ãµes de Troubleshooting acima
2. Verificar logs dos containers (`docker logs <container>`)
3. Consultar documentaÃ§Ã£o detalhada:
   - B1: `resultados/B1/RELATORIO_FINAL_COMPLETO.md`
   - B2: `resultados_spark/IMPLEMENTACAO_B2_COMPLETA.md`
   - ML: `resultados_spark/EXTENSAO_ML_SENTIMENTOS.md`

---

**Ãšltima atualizaÃ§Ã£o:** 29/11/2025  
**VersÃ£o:** 1.0  
**Arquivo:** `/home/edilberto/pspd/atividade-extraclasse-2-pspd/como_executar.md`
