# Atividade Extraclasse 2 - PSPD

[![Docker](https://img.shields.io/badge/Docker-20.10%2B-blue.svg)](https://www.docker.com/)
[![Hadoop](https://img.shields.io/badge/Hadoop-3.3.6-yellow.svg)](https://hadoop.apache.org/)
[![Spark](https://img.shields.io/badge/Spark-3.5.0-orange.svg)](https://spark.apache.org/)
[![License](https://img.shields.io/badge/License-Academic-green.svg)](LICENSE)

Projeto de estudo sobre processamento distribuÃ­do usando Hadoop e Spark em containers Docker.

> ğŸš€ **[GUIA COMPLETO DE EXECUÃ‡ÃƒO](como_executar.md)** - InstruÃ§Ãµes detalhadas passo a passo para executar todo o projeto do zero

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [InÃ­cio RÃ¡pido](#inÃ­cio-rÃ¡pido)
- [Requisitos](#requisitos)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [DocumentaÃ§Ã£o](#documentaÃ§Ã£o)

## ğŸ¯ VisÃ£o Geral

Este projeto implementa e testa clusters Hadoop e Spark para anÃ¡lise de desempenho com diferentes configuraÃ§Ãµes.

### ImplementaÃ§Ãµes

**B1 - Hadoop MapReduce**
- Cluster distribuÃ­do (1 master + 2 workers)
- 5 configuraÃ§Ãµes diferentes testadas
- Testes de tolerÃ¢ncia a falhas
- Testes de concorrÃªncia
- Dataset massivo (500MB+)

**B2 - Spark Streaming**
- Pipeline de processamento em tempo real
- IntegraÃ§Ã£o Kafka + Elasticsearch + Kibana
- Producer/Consumer autocontidos
- Dashboard de visualizaÃ§Ã£o

**ExtensÃ£o ML (Opcional)**
- AnÃ¡lise de sentimentos com VADER
- ClassificaÃ§Ã£o automÃ¡tica de polaridade
- VisualizaÃ§Ãµes enriquecidas no Kibana

## âš¡ InÃ­cio RÃ¡pido

### B1 - Hadoop (3 comandos)
```bash
cd hadoop && docker-compose up -d
cd .. && ./scripts/run_all_tests.sh
cat resultados/B1/RELATORIO_FINAL_COMPLETO.md
```

### B2 - Spark (2 passos)
```bash
cd spark && docker-compose up -d
# Abrir spark/notebooks/B2_SPARK_STREAMING_COMPLETO.ipynb e executar cÃ©lulas
```

> ğŸ“– **Para instruÃ§Ãµes detalhadas**, consulte **[como_executar.md](como_executar.md)**

## âš™ï¸ Requisitos

- Docker 20.10+
- Docker Compose 2.0+
- Python 3.8+
- 8GB RAM disponÃ­vel
- 20GB espaÃ§o em disco

## ğŸ› ï¸ Estrutura do Projeto

```
atividade-extraclasse-2-pspd/
â”œâ”€â”€ como_executar.md           # ğŸ“– GUIA PRINCIPAL DE EXECUÃ‡ÃƒO
â”œâ”€â”€ README.md                  # Este arquivo (visÃ£o geral)
â”œâ”€â”€ STATUS_IMPLEMENTACAO.md    # Status das implementaÃ§Ãµes B1/B2
â”‚
â”œâ”€â”€ hadoop/                    # B1: Cluster Hadoop
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ master/worker1/worker2/
â”‚
â”œâ”€â”€ spark/                     # B2: Spark Streaming
â”‚   â”œâ”€â”€ docker-compose.yml     # Kafka + ES + Kibana
â”‚   â””â”€â”€ notebooks/
â”‚       â””â”€â”€ B2_SPARK_STREAMING_COMPLETO.ipynb  # Notebook principal (65 cÃ©lulas)
â”‚
â”œâ”€â”€ scripts/                   # Scripts de teste e automaÃ§Ã£o
â”‚   â”œâ”€â”€ run_all_tests.sh       # Executar todos os testes B1
â”‚   â”œâ”€â”€ test_fault_tolerance.sh
â”‚   â”œâ”€â”€ test_concurrency.sh
â”‚   â””â”€â”€ collect_metrics.sh
â”‚
â”œâ”€â”€ config/                    # ConfiguraÃ§Ãµes XML por teste
â”‚   â”œâ”€â”€ teste1_memoria/
â”‚   â”œâ”€â”€ teste2_replicacao/
â”‚   â”œâ”€â”€ teste3_blocksize/
â”‚   â”œâ”€â”€ teste4_reducers/
â”‚   â””â”€â”€ teste5_speculative/
â”‚
â”œâ”€â”€ resultados/B1/             # Resultados Hadoop
â”‚   â”œâ”€â”€ RELATORIO_FINAL_COMPLETO.md
â”‚   â”œâ”€â”€ teste0_baseline/
â”‚   â”œâ”€â”€ teste1_memoria/
â”‚   â”œâ”€â”€ teste2_replicacao/
â”‚   â”œâ”€â”€ teste3_blocksize/
â”‚   â”œâ”€â”€ teste4_reducers/
â”‚   â”œâ”€â”€ teste5_speculative/
â”‚   â”œâ”€â”€ teste_tolerancia_falhas/
â”‚   â””â”€â”€ teste_concorrencia/
â”‚
â”œâ”€â”€ resultados_spark/          # Resultados Spark
â”‚   â”œâ”€â”€ IMPLEMENTACAO_B2_COMPLETA.md
â”‚   â”œâ”€â”€ VALIDACAO_B2_DETALHADA.md
â”‚   â”œâ”€â”€ EXTENSAO_ML_SENTIMENTOS.md
â”‚   â””â”€â”€ kibana_*.png           # Screenshots (pendente)
â”‚
â””â”€â”€ docs/                      # DocumentaÃ§Ã£o tÃ©cnica adicional
    â”œâ”€â”€ hadoop.md
    â”œâ”€â”€ spark.md
    â””â”€â”€ tests.md
```

## ğŸ“š DocumentaÃ§Ã£o

### DocumentaÃ§Ã£o Principal
- **[como_executar.md](como_executar.md)** - ğŸš€ Guia completo de execuÃ§Ã£o passo a passo (B1 + B2 + ML)
- **[STATUS_IMPLEMENTACAO.md](STATUS_IMPLEMENTACAO.md)** - Status e checklist das implementaÃ§Ãµes

### DocumentaÃ§Ã£o B1 (Hadoop)
- **[resultados/B1/RELATORIO_FINAL_COMPLETO.md](resultados/B1/RELATORIO_FINAL_COMPLETO.md)** - RelatÃ³rio consolidado dos testes
- **[docs/hadoop.md](docs/hadoop.md)** - DocumentaÃ§Ã£o tÃ©cnica Hadoop

### DocumentaÃ§Ã£o B2 (Spark)
- **[resultados_spark/IMPLEMENTACAO_B2_COMPLETA.md](resultados_spark/IMPLEMENTACAO_B2_COMPLETA.md)** - DocumentaÃ§Ã£o detalhada da implementaÃ§Ã£o
- **[resultados_spark/VALIDACAO_B2_DETALHADA.md](resultados_spark/VALIDACAO_B2_DETALHADA.md)** - Checklist de validaÃ§Ã£o
- **[resultados_spark/EXTENSAO_ML_SENTIMENTOS.md](resultados_spark/EXTENSAO_ML_SENTIMENTOS.md)** - DocumentaÃ§Ã£o da extensÃ£o ML
- **[docs/spark.md](docs/spark.md)** - DocumentaÃ§Ã£o tÃ©cnica Spark

## ğŸ“ Suporte

Para executar o projeto, consulte primeiro **[como_executar.md](como_executar.md)**.

Para troubleshooting:
1. Verificar seÃ§Ã£o de troubleshooting em `como_executar.md`
2. Consultar logs dos containers: `docker logs <container-name>`
3. Verificar documentaÃ§Ã£o tÃ©cnica especÃ­fica em `docs/`

## ğŸ“ LicenÃ§a

Projeto acadÃªmico - Disciplina de ProgramaÃ§Ã£o para Sistemas Paralelos e DistribuÃ­dos.

## ğŸ‘¤ Autor

**Edilberto CantuÃ¡ria**

---

**Ãšltima atualizaÃ§Ã£o**: 29/11/2025
