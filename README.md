# Atividade Extraclasse 2 - PSPD

[![Docker](https://img.shields.io/badge/Docker-20.10%2B-blue.svg)](https://www.docker.com/)
[![Hadoop](https://img.shields.io/badge/Hadoop-3.3.6-yellow.svg)](https://hadoop.apache.org/)
[![Spark](https://img.shields.io/badge/Spark-3.5.0-orange.svg)](https://spark.apache.org/)
[![License](https://img.shields.io/badge/License-Academic-green.svg)](LICENSE)

Projeto de estudo sobre processamento distribuÃ­do usando Hadoop e Spark em containers Docker.

> ğŸ“˜ **DocumentaÃ§Ã£o Adicional**: [CHANGELOG](CHANGELOG.md) | [CONTRIBUTING](CONTRIBUTING.md) | [SUMMARY](SUMMARY.md)

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Requisitos](#requisitos)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Uso](#uso)
  - [Hadoop (B1)](#hadoop-b1)
  - [Spark (B2)](#spark-b2)
- [Arquitetura](#arquitetura)
- [Testes](#testes)
- [Resultados](#resultados)
- [DocumentaÃ§Ã£o](#documentaÃ§Ã£o)

## ğŸ¯ VisÃ£o Geral

Este projeto implementa e testa clusters Hadoop e Spark para anÃ¡lise de desempenho com diferentes configuraÃ§Ãµes. Inclui:

- **Hadoop**: Cluster com 1 master + 2 workers para testes MapReduce
- **Spark**: Ambiente integrado com Kafka, Elasticsearch e Kibana
- **Testes automatizados**: Scripts para avaliar impacto de configuraÃ§Ãµes
- **AnÃ¡lise de falhas**: Testes de resiliÃªncia e recuperaÃ§Ã£o

## âš™ï¸ Requisitos

- Docker 20.10+
- Docker Compose 2.0+
- 8GB RAM disponÃ­vel
- 20GB espaÃ§o em disco

## ğŸš€ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/edilbertocantuaria/atividade-extraclasse-2-pspd.git
cd atividade-extraclasse-2-pspd

# Tornar scripts executÃ¡veis
chmod +x scripts/*.sh
```

## ğŸ’» Uso

### Hadoop (B1)

#### Iniciar Cluster

```bash
./scripts/setup.sh
```

Interfaces disponÃ­veis:
- **HDFS UI**: http://localhost:9870
- **YARN UI**: http://localhost:8088

#### Executar Testes

```bash
./scripts/run_tests.sh
```

Os testes avaliam o impacto de:
1. **MemÃ³ria YARN** (1024MB vs padrÃ£o)
2. **ReplicaÃ§Ã£o HDFS** (1 vs 2 rÃ©plicas)
3. **Block Size** (64MB vs 128MB)
4. **Reducers** (1, 2, 4 reducers)

#### Limpar Ambiente

```bash
./scripts/cleanup.sh
```

### Spark (B2)

#### Iniciar Ambiente Spark

```bash
cd spark
docker compose up -d
```

Interfaces disponÃ­veis:
- **Spark UI**: http://localhost:8080
- **Kibana**: http://localhost:5601
- **Jupyter**: http://localhost:8888

#### Executar Testes Spark

```bash
./spark/testar_ambiente.sh
```

## ğŸ—ï¸ Arquitetura

### Hadoop Cluster

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  hadoop-master  â”‚
â”‚  - NameNode     â”‚
â”‚  - ResourceMgr  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”
â”‚worker1â”‚  â”‚worker2â”‚
â”‚DataNodeâ”‚ â”‚DataNodeâ”‚
â”‚NodeMgr â”‚ â”‚NodeMgr â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ConfiguraÃ§Ãµes Principais

| Componente | Arquivo | ConfiguraÃ§Ã£o Principal |
|------------|---------|------------------------|
| HDFS | `hdfs-site.xml` | ReplicaÃ§Ã£o: 2, BlockSize: 128MB |
| YARN | `yarn-site.xml` | Memory: 2048MB por NodeManager |
| MapReduce | `mapred-site.xml` | Framework: YARN |

## ğŸ§ª Testes

### B1 - Testes Hadoop

Os testes usam WordCount em um dataset gerado automaticamente:

```bash
# Verificar ambiente antes de testar
./scripts/verify.sh

# Executar todos os testes B1
./scripts/run_tests.sh
```

**MÃ©tricas coletadas:**
- Tempo total de execuÃ§Ã£o
- Tempo de Map
- Tempo de Reduce
- CPU e MemÃ³ria usadas
- Bytes lidos/escritos HDFS

### B2 - Testes Spark

Testes com streaming Kafka e visualizaÃ§Ã£o:

```bash
cd spark
./testar_ambiente.sh
```

## ğŸ“Š Resultados

Os resultados sÃ£o salvos automaticamente em:

```
resultados/
â”œâ”€â”€ B1/
â”‚   â”œâ”€â”€ teste1_memoria/
â”‚   â”œâ”€â”€ teste2_replicacao/
â”‚   â”œâ”€â”€ teste3_blocksize/
â”‚   â”œâ”€â”€ teste4_reducers/
â”‚   â”œâ”€â”€ resumo_comparativo.txt
â”‚   â””â”€â”€ relatorio_consolidado.txt
â””â”€â”€ ...

resultados_spark/
â”œâ”€â”€ relatorio_final_spark.md
â”œâ”€â”€ testes_graficos.md
â””â”€â”€ VALIDACAO_B2.md
```

### Visualizar Resultados

```bash
# Resumo comparativo dos testes B1
cat resultados/B1/resumo_comparativo.txt

# RelatÃ³rio detalhado
cat resultados/B1/relatorio_consolidado.txt

# Resultados Spark
cat resultados_spark/relatorio_final_spark.md
```

## ğŸ“š DocumentaÃ§Ã£o

DocumentaÃ§Ã£o detalhada disponÃ­vel em [`docs/`](docs/):

- [**Hadoop**](docs/hadoop.md): Arquitetura, configuraÃ§Ãµes e troubleshooting
- [**Spark**](docs/spark.md): Setup do ambiente integrado com Kafka/Elastic
- [**Testes**](docs/tests.md): Metodologia e anÃ¡lise de resultados

## ğŸ› ï¸ Estrutura do Projeto

```
.
â”œâ”€â”€ README.md                  # Este arquivo
â”œâ”€â”€ scripts/                   # Scripts principais
â”‚   â”œâ”€â”€ setup.sh              # Iniciar cluster Hadoop
â”‚   â”œâ”€â”€ run_tests.sh          # Executar testes B1
â”‚   â”œâ”€â”€ cleanup.sh            # Limpar ambiente
â”‚   â””â”€â”€ verify.sh             # Verificar configuraÃ§Ãµes
â”œâ”€â”€ hadoop/                    # ConfiguraÃ§Ãµes Hadoop
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ master/worker1/worker2/ # Configs XML por nÃ³
â”œâ”€â”€ spark/                     # Ambiente Spark
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ spark_app/
â”œâ”€â”€ config/                    # ConfiguraÃ§Ãµes de teste
â”‚   â”œâ”€â”€ teste1_memoria/
â”‚   â”œâ”€â”€ teste2_replicacao/
â”‚   â”œâ”€â”€ teste3_blocksize/
â”‚   â””â”€â”€ teste4_reducers/
â”œâ”€â”€ resultados/                # Outputs dos testes
â”œâ”€â”€ docs/                      # DocumentaÃ§Ã£o detalhada
â””â”€â”€ wordcount/                 # AplicaÃ§Ã£o WordCount

```

## ğŸ“ LicenÃ§a

Este Ã© um projeto acadÃªmico para a disciplina de ProgramaÃ§Ã£o para Sistemas Paralelos e DistribuÃ­dos.

## ğŸ‘¤ Autor

**Edilberto CantuÃ¡ria**

---

**Ãšltima atualizaÃ§Ã£o**: Novembro 2025
