# Comandos RÃ¡pidos - Hadoop B1

## ðŸš€ InÃ­cio RÃ¡pido (3 comandos)

```bash
cd /home/edilberto/pspd/atividade-extraclasse-2-pspd/hadoop
docker-compose up -d
cd .. && ./scripts/run_all_tests.sh
```

---

## ðŸ“¦ Gerenciamento do Cluster

### Iniciar Cluster
```bash
cd /home/edilberto/pspd/atividade-extraclasse-2-pspd/hadoop
docker-compose up -d
```

### Parar Cluster
```bash
docker-compose down
```

### Ver Status
```bash
docker ps | grep hadoop
```

### Logs
```bash
# Master
docker logs hadoop-master -f

# Worker1
docker logs hadoop-worker1 -f

# Worker2
docker logs hadoop-worker2 -f
```

### Acessar Container
```bash
docker exec -it hadoop-master bash
```

---

## ðŸ§ª Executar Testes

### Todos os Testes (AutomÃ¡tico)
```bash
./scripts/run_all_tests.sh
```

### Gerar Dataset
```bash
# 500MB (padrÃ£o)
./scripts/generate_large_dataset.sh 500

# 1GB (para testes mais longos)
./scripts/generate_large_dataset.sh 1000

# 2GB (para testes muito longos)
./scripts/generate_large_dataset.sh 2000
```

### Teste de TolerÃ¢ncia a Falhas
```bash
./scripts/test_fault_tolerance.sh
# DuraÃ§Ã£o: ~15-20 minutos
```

### Teste de ConcorrÃªncia
```bash
./scripts/test_concurrency.sh
# DuraÃ§Ã£o: ~10-15 minutos
```

### Coletar MÃ©tricas de um Job
```bash
# Primeiro execute um job e pegue o Application ID
./scripts/collect_metrics.sh application_1234567890123_0001 resultados/B1/meu_teste 500
```

---

## ðŸ“Š Monitoramento

### Interface Web YARN ResourceManager
```bash
# No navegador:
http://localhost:8088
```

### Interface Web HDFS NameNode
```bash
# No navegador:
http://localhost:9870
```

### Listar AplicaÃ§Ãµes YARN
```bash
docker exec hadoop-master yarn application -list
docker exec hadoop-master yarn application -list -appStates ALL
```

### Status de uma AplicaÃ§Ã£o
```bash
docker exec hadoop-master yarn application -status application_1234567890123_0001
```

### Ver Logs de uma AplicaÃ§Ã£o
```bash
docker exec hadoop-master yarn logs -applicationId application_1234567890123_0001
```

### Status do Cluster YARN
```bash
docker exec hadoop-master yarn node -list -all
```

### RelatÃ³rio do HDFS
```bash
docker exec hadoop-master hdfs dfsadmin -report
```

### Verificar SaÃºde HDFS
```bash
docker exec hadoop-master hdfs dfsadmin -safemode get
docker exec hadoop-master hdfs fsck / -files -blocks -locations
```

---

## ðŸ’¾ Gerenciamento HDFS

### Listar Arquivos
```bash
docker exec hadoop-master hdfs dfs -ls /
docker exec hadoop-master hdfs dfs -ls /user/hadoop/input
docker exec hadoop-master hdfs dfs -ls -h -R /user/hadoop
```

### Upload para HDFS
```bash
docker exec hadoop-master hdfs dfs -put /caminho/local /user/hadoop/input/
```

### Download do HDFS
```bash
docker exec hadoop-master hdfs dfs -get /user/hadoop/output/resultado /tmp/
docker cp hadoop-master:/tmp/resultado ./local/
```

### Ver ConteÃºdo de Arquivo
```bash
docker exec hadoop-master hdfs dfs -cat /user/hadoop/output/part-r-00000
docker exec hadoop-master hdfs dfs -cat /user/hadoop/output/part-r-00000 | head -20
```

### Deletar Arquivos
```bash
docker exec hadoop-master hdfs dfs -rm /user/hadoop/output/arquivo.txt
docker exec hadoop-master hdfs dfs -rm -r /user/hadoop/output/diretorio
```

### EspaÃ§o Utilizado
```bash
docker exec hadoop-master hdfs dfs -df -h
docker exec hadoop-master hdfs dfs -du -h /user/hadoop
```

---

## ðŸ”§ Executar WordCount Manualmente

### BÃ¡sico
```bash
docker exec hadoop-master bash -c "
  hdfs dfs -rm -r -f /user/hadoop/output/test
  hadoop jar /home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar \
    wordcount /user/hadoop/input /user/hadoop/output/test
"
```

### Com MediÃ§Ã£o de Tempo
```bash
docker exec hadoop-master bash -c "
  hdfs dfs -rm -r -f /user/hadoop/output/test
  time hadoop jar /home/hadoop/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar \
    wordcount /user/hadoop/input /user/hadoop/output/test
"
```

### Ver Top 10 Palavras
```bash
docker exec hadoop-master bash -c "
  hdfs dfs -cat /user/hadoop/output/test/part-r-00000 | sort -k2 -nr | head -10
"
```

---

## ðŸŽ›ï¸ Controlar Workers

### Parar Worker
```bash
docker stop hadoop-worker1
# ou
docker stop hadoop-worker2
```

### Iniciar Worker
```bash
docker start hadoop-worker1
# ou
docker start hadoop-worker2
```

### Reiniciar Worker
```bash
docker restart hadoop-worker1
```

### Ver Status de Todos
```bash
docker ps --filter "name=hadoop-" --format "table {{.Names}}\t{{.Status}}"
```

---

## ðŸ“ˆ AnÃ¡lise de Resultados

### Ver Todos os Tempos de ExecuÃ§Ã£o
```bash
for dir in resultados/B1/teste*/; do
  test_name=$(basename "$dir")
  duration=$(cat "$dir/time_stats.txt" 2>/dev/null || echo "N/A")
  echo "$test_name: ${duration}s"
done
```

### Ver RelatÃ³rio Final
```bash
cat resultados/B1/relatorio_final_completo.md
```

### Ver RelatÃ³rio de TolerÃ¢ncia a Falhas
```bash
cat resultados/B1/teste_tolerancia_falhas/run_*/relatorio_tolerancia_falhas.md
```

### Ver RelatÃ³rio de ConcorrÃªncia
```bash
cat resultados/B1/teste_concorrencia/run_*/relatorio_concorrencia.md
```

### Ver MÃ©tricas CSV
```bash
# Ver todas as mÃ©tricas
cat resultados/B1/teste*/metrics_summary.csv

# Consolidar em uma tabela
echo "Teste,Metric,Value,Unit"
for dir in resultados/B1/teste*/; do
  test_name=$(basename "$dir")
  if [ -f "$dir/metrics_summary.csv" ]; then
    tail -n +2 "$dir/metrics_summary.csv" | sed "s/^/$test_name,/"
  fi
done
```

### Comparar Tempos Graficamente (Python)
```bash
cat > /tmp/plot_results.py << 'EOF'
import matplotlib.pyplot as plt
import os

tests = []
times = []

for dir_name in sorted(os.listdir('resultados/B1')):
    if dir_name.startswith('teste'):
        time_file = f'resultados/B1/{dir_name}/time_stats.txt'
        if os.path.exists(time_file):
            with open(time_file) as f:
                tests.append(dir_name.replace('teste', 'T').replace('_', ' ').title())
                times.append(float(f.read().strip()))

plt.figure(figsize=(10, 6))
plt.bar(tests, times, color='steelblue')
plt.xlabel('ConfiguraÃ§Ã£o', fontsize=12)
plt.ylabel('DuraÃ§Ã£o (segundos)', fontsize=12)
plt.title('ComparaÃ§Ã£o de Desempenho - Testes Hadoop', fontsize=14)
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.savefig('resultados/B1/comparison_chart.png', dpi=150)
print("GrÃ¡fico salvo: resultados/B1/comparison_chart.png")
EOF

python3 /tmp/plot_results.py
```

---

## ðŸ§¹ Limpeza

### Limpar Outputs HDFS
```bash
docker exec hadoop-master hdfs dfs -rm -r -f /user/hadoop/output/*
```

### Limpar Logs
```bash
docker exec hadoop-master bash -c "rm -rf /home/hadoop/hadoop/logs/*"
```

### Reset Completo (CUIDADO!)
```bash
./scripts/cleanup.sh
# ou manualmente:
docker-compose down -v
docker volume prune -f
```

---

## ðŸ› Troubleshooting

### Cluster nÃ£o responde
```bash
# Ver logs de erro
docker logs hadoop-master --tail 100

# Reiniciar serviÃ§os
docker exec hadoop-master bash -c "
  /home/hadoop/hadoop/sbin/stop-all.sh
  sleep 10
  /home/hadoop/hadoop/sbin/start-all.sh
"
```

### Job travado
```bash
# Listar jobs em execuÃ§Ã£o
docker exec hadoop-master yarn application -list -appStates RUNNING

# Matar job
docker exec hadoop-master yarn application -kill application_1234567890123_0001
```

### HDFS em safe mode
```bash
# Verificar
docker exec hadoop-master hdfs dfsadmin -safemode get

# ForÃ§ar saÃ­da (CUIDADO!)
docker exec hadoop-master hdfs dfsadmin -safemode leave
```

### Sem espaÃ§o em disco
```bash
# Ver uso
docker exec hadoop-master df -h

# Limpar outputs
docker exec hadoop-master hdfs dfs -rm -r -f /user/hadoop/output/*

# Limpar Docker
docker system prune -a
```

### Workers nÃ£o conectam
```bash
# Ver nÃ³s ativos
docker exec hadoop-master yarn node -list -all

# Reiniciar workers
docker restart hadoop-worker1 hadoop-worker2

# Ver logs de worker
docker logs hadoop-worker1 --tail 50
```

---

## ðŸ“± Atalhos Ãšteis

### Ver Tudo de Uma Vez
```bash
echo "=== CLUSTER STATUS ==="
docker ps --filter "name=hadoop-" --format "table {{.Names}}\t{{.Status}}"
echo ""
echo "=== YARN NODES ==="
docker exec hadoop-master yarn node -list 2>/dev/null
echo ""
echo "=== HDFS SUMMARY ==="
docker exec hadoop-master hdfs dfs -df -h 2>/dev/null
echo ""
echo "=== RECENT APPS ==="
docker exec hadoop-master yarn application -list -appStates ALL 2>/dev/null | head -10
```

### Monitorar Job em Tempo Real
```bash
APP_ID="application_1234567890123_0001"
watch -n 5 "docker exec hadoop-master yarn application -status $APP_ID 2>/dev/null | grep -E 'State|Progress|Final'"
```

### Contar Palavras do Resultado
```bash
docker exec hadoop-master bash -c "
  hdfs dfs -cat /user/hadoop/output/*/part-r-* 2>/dev/null | \
  awk '{sum+=\$2} END {print \"Total palavras Ãºnicas:\", NR; print \"Total ocorrÃªncias:\", sum}'
"
```

---

## ðŸ“– ReferÃªncias RÃ¡pidas

- **Guia Completo**: `docs/GUIA_EXECUCAO_HADOOP.md`
- **Resumo de ImplementaÃ§Ã£o**: `RESUMO_IMPLEMENTACAO_B1.md`
- **README**: `README.md`

---

**Dica**: Adicione este arquivo aos favoritos para consulta rÃ¡pida!
