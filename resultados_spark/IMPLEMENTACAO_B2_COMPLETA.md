# Implementa√ß√£o B2 - Spark Structured Streaming (COMPLETA)

**Data:** 29 de Novembro de 2025  
**Disciplina:** PSPD - Programa√ß√£o para Sistemas Paralelos e Distribu√≠dos  
**Atividade:** Extra-Classe 2 - Parte B2

---

## ‚úÖ Status: IMPLEMENTA√á√ÉO COMPLETA

Todos os requisitos da parte B2 foram implementados no notebook autocontido:

üìì **Arquivo:** `spark/notebooks/B2_SPARK_STREAMING_COMPLETO.ipynb`

---

## üìã Checklist de Requisitos

### ‚úÖ 1. Entrada via Rede Social com Kafka

#### ‚úÖ 1.1 Justificativa para Alternativa ao Discord
- **Localiza√ß√£o:** Se√ß√£o 1 do notebook (c√©lulas 1-2)
- **Conte√∫do:**
  - Explica√ß√£o detalhada das limita√ß√µes t√©cnicas do Discord
  - Raz√µes de inviabilidade: OAuth complexo, WebSocket persistente, rate limits
  - Alternativa escolhida: Producer Python com gera√ß√£o sint√©tica
  - Vantagens da alternativa: reprodutibilidade, controle total, sem depend√™ncias externas

#### ‚úÖ 1.2 Producer Kafka Implementado
- **Localiza√ß√£o:** Se√ß√£o 3 do notebook (c√©lulas 11-17)
- **Classe:** `SocialMediaProducer`
- **Funcionalidades:**
  - Gera√ß√£o de mensagens JSON simulando rede social
  - Campos: `user`, `text`, `timestamp`, `platform`, `message_id`
  - Dataset sint√©tico com 15 mensagens realistas sobre Big Data
  - Taxa configur√°vel (padr√£o: 3 msgs/seg)
  - Execu√ß√£o em background thread
  - Contador de mensagens enviadas

#### ‚úÖ 1.3 Documenta√ß√£o da Implementa√ß√£o
- **Localiza√ß√£o:** Se√ß√£o 1 e 3 do notebook
- **Conte√∫do:**
  - C√≥digo completo do producer comentado
  - Explica√ß√£o do formato JSON das mensagens
  - Instru√ß√µes de execu√ß√£o
  - Teste de envio de amostra (20 mensagens)
  - Verifica√ß√£o de mensagens no t√≥pico Kafka

---

### ‚úÖ 2. Pipeline Spark Structured Streaming

#### ‚úÖ 2.1 Configura√ß√£o e Leitura do Stream
- **Localiza√ß√£o:** Se√ß√£o 4 do notebook (c√©lulas 19-23)
- **Implementa√ß√£o:**
  - Sess√£o Spark com suporte Kafka (pacote `spark-sql-kafka-0-10`)
  - Schema JSON definido para mensagens de entrada
  - Leitura do t√≥pico `social-input`
  - Deserializa√ß√£o JSON com `from_json()`

#### ‚úÖ 2.2 Processamento Word Count
- **Localiza√ß√£o:** Se√ß√£o 4.4 do notebook (c√©lula 24)
- **Pipeline:**
  1. Extra√ß√£o de palavras com `split()` e `explode()`
  2. Normaliza√ß√£o: lowercase e remo√ß√£o de pontua√ß√£o
  3. Agrega√ß√£o com janelas temporais (30s, slide 10s)
  4. Watermark de 1 minuto para eventos atrasados
  5. Contagem por palavra e janela

#### ‚úÖ 2.3 Publica√ß√£o no T√≥pico de Sa√≠da
- **Localiza√ß√£o:** Se√ß√£o 4.5 do notebook (c√©lula 25)
- **Implementa√ß√£o:**
  - Convers√£o para JSON com `to_json(struct())`
  - Escrita no t√≥pico `wordcount-output`
  - Checkpoint para recupera√ß√£o de falhas
  - Output mode: `update`

#### ‚úÖ 2.4 Visualiza√ß√£o Debug
- **Localiza√ß√£o:** Se√ß√£o 4.6 do notebook (c√©lula 26)
- **Funcionalidade:**
  - Query adicional para console (debug)
  - Mostra top 20 word counts em tempo real
  - √ötil para valida√ß√£o durante desenvolvimento

---

### ‚úÖ 3. Consumer Elasticsearch

#### ‚úÖ 3.1 Cria√ß√£o do √çndice
- **Localiza√ß√£o:** Se√ß√£o 6.1 do notebook (c√©lula 37)
- **Configura√ß√£o:**
  - √çndice: `wordcount-realtime`
  - Mapping otimizado:
    - `word`: keyword (para agrega√ß√µes)
    - `count`: integer
    - `window_start`: date
    - `window_end`: date
    - `indexed_at`: date (timestamp de indexa√ß√£o)

#### ‚úÖ 3.2 Consumer Kafka ‚Üí Elasticsearch
- **Localiza√ß√£o:** Se√ß√£o 6.2 do notebook (c√©lula 38)
- **Classe:** `ElasticsearchConsumer`
- **Funcionalidades:**
  - Consumo do t√≥pico `wordcount-output`
  - Deserializa√ß√£o JSON autom√°tica
  - Indexa√ß√£o em batch (30 documentos por vez)
  - Execu√ß√£o em background thread
  - Contador de documentos indexados
  - Tratamento de erros e cleanup

#### ‚úÖ 3.3 Execu√ß√£o e Valida√ß√£o
- **Localiza√ß√£o:** Se√ß√µes 6.3 e 6.4 do notebook (c√©lulas 39-41)
- **Funcionalidades:**
  - Inicializa√ß√£o do consumer em thread separada
  - Aguardar 90s para acumular dados
  - Verifica√ß√£o da contagem de documentos
  - Amostra dos top 10 word counts indexados

---

### ‚úÖ 4. Dashboard Kibana

#### ‚úÖ 4.1 Instru√ß√µes Detalhadas para Tag Cloud
- **Localiza√ß√£o:** Se√ß√£o 7.1 do notebook (c√©lula 42)
- **Passo a Passo Completo:**

**Passo 1: Acessar Kibana**
- URL: http://localhost:5601
- Aguardar carregamento

**Passo 2: Criar Index Pattern**
- Stack Management ‚Üí Data Views ‚Üí Create data view
- Name: `WordCount Real-Time`
- Index pattern: `wordcount-realtime*`
- Timestamp field: `window_start`

**Passo 3: Criar Visualiza√ß√£o Tag Cloud**
- Visualize Library ‚Üí Create visualization
- Tipo: Tag Cloud
- Configura√ß√£o:
  - Buckets ‚Üí Tags:
    - Aggregation: `Terms`
    - Field: `word.keyword`
    - Order By: `Metric: Count`
    - Order: `Descending`
    - Size: `50` (top 50 palavras)
  - Metrics:
    - Aggregation: `Sum`
    - Field: `count`
- Update e Save: `Word Cloud - Social Media Stream`

**Passo 4: Criar Dashboard**
- Dashboard ‚Üí Create dashboard
- Adicionar visualiza√ß√µes:
  - Word Cloud principal
  - Vertical Bar: Count por janela temporal
  - Data Table: Top 20 palavras
  - Metric: Total de palavras √∫nicas
- Auto-refresh: 10 segundos
- Save: `B2 - Real-Time Word Count Analytics`

#### ‚úÖ 4.2 Alternativas ao Tag Cloud
- **Localiza√ß√£o:** Se√ß√£o 7.2 do notebook (c√©lula 42)
- **3 Alternativas Documentadas:**

**Op√ß√£o A: Horizontal Bar Chart**
- Tipo: `Horizontal Bar`
- Y-axis: `word.keyword` (Terms, top 30)
- X-axis: `count` (Sum)
- Uso: Palavras mais frequentes em barras horizontais

**Op√ß√£o B: Data Table**
- Tipo: `Data Table`
- Rows: `word.keyword` (Terms, top 50)
- Metrics: `count` (Sum)
- Uso: Tabela ordenada por contagem

**Op√ß√£o C: Treemap**
- Tipo: `Treemap`
- Groups: `word.keyword` (Terms, top 40)
- Size: `count` (Sum)
- Uso: Blocos proporcionais √† frequ√™ncia

#### ‚úÖ 4.3 Instru√ß√µes para Screenshots
- **Localiza√ß√£o:** Se√ß√£o 7.3 do notebook (c√©lula 42)
- **A√ß√£o Manual Requerida:**
  1. Capturar screenshot do dashboard completo
  2. Salvar: `resultados_spark/kibana_dashboard_wordcloud.png`
  3. Capturar Tag Cloud isolada
  4. Salvar: `resultados_spark/kibana_tagcloud_detail.png`

#### ‚úÖ 4.4 Verifica√ß√£o via API
- **Localiza√ß√£o:** Se√ß√£o 7.4 do notebook (c√©lula 43)
- **Funcionalidades:**
  - Verifica√ß√£o de status do Kibana
  - Estat√≠sticas do √≠ndice Elasticsearch
  - Contagem de documentos
  - Tamanho em disco

---

## üèóÔ∏è Arquitetura Implementada

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Producer Python    ‚îÇ  (Se√ß√£o 3)
‚îÇ  SocialMedia        ‚îÇ  - Gera√ß√£o sint√©tica
‚îÇ  Simulator          ‚îÇ  - 3 msgs/seg
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Kafka Topic        ‚îÇ
‚îÇ  social-input       ‚îÇ  (Se√ß√£o 2.4)
‚îÇ  (3 partitions)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Spark Streaming    ‚îÇ  (Se√ß√£o 4)
‚îÇ  - Read Stream      ‚îÇ  - Window 30s/10s
‚îÇ  - Word Count       ‚îÇ  - Watermark 1min
‚îÇ  - Aggregation      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ      ‚îÇ
       ‚îÇ      ‚ñº
       ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ   ‚îÇ  Console Debug  ‚îÇ  (Se√ß√£o 4.6)
       ‚îÇ   ‚îÇ  (20 rows)      ‚îÇ
       ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Kafka Topic        ‚îÇ
‚îÇ  wordcount-output   ‚îÇ  (Se√ß√£o 4.5)
‚îÇ  (3 partitions)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ES Consumer        ‚îÇ  (Se√ß√£o 6)
‚îÇ  - Batch indexing   ‚îÇ  - Batch size: 30
‚îÇ  - Background       ‚îÇ  - Duration: 120s
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Elasticsearch      ‚îÇ  (Se√ß√£o 6.1)
‚îÇ  Index:             ‚îÇ
‚îÇ  wordcount-realtime ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Kibana Dashboard   ‚îÇ  (Se√ß√£o 7)
‚îÇ  - Tag Cloud        ‚îÇ  - Instru√ß√µes completas
‚îÇ  - Metrics          ‚îÇ  - 3 alternativas
‚îÇ  - Time Series      ‚îÇ  - Screenshots pending
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Par√¢metros de Configura√ß√£o

| Componente | Par√¢metro | Valor | Localiza√ß√£o |
|------------|-----------|-------|-------------|
| **Producer** | Taxa de mensagens | 3 msgs/seg | Se√ß√£o 5.1, c√©lula 31 |
| **Producer** | Dura√ß√£o | 180 segundos | Se√ß√£o 5.1, c√©lula 31 |
| **Producer** | Dataset | 15 mensagens + 8 usu√°rios | Se√ß√£o 3.2, c√©lula 13 |
| **Kafka Input** | T√≥pico | `social-input` | Se√ß√£o 2.4, c√©lula 9 |
| **Kafka Input** | Parti√ß√µes | 3 | Se√ß√£o 2.4, c√©lula 9 |
| **Kafka Output** | T√≥pico | `wordcount-output` | Se√ß√£o 2.4, c√©lula 9 |
| **Kafka Output** | Parti√ß√µes | 3 | Se√ß√£o 2.4, c√©lula 9 |
| **Spark** | Janela temporal | 30 segundos | Se√ß√£o 4.4, c√©lula 24 |
| **Spark** | Slide | 10 segundos | Se√ß√£o 4.4, c√©lula 24 |
| **Spark** | Watermark | 1 minuto | Se√ß√£o 4.4, c√©lula 24 |
| **Spark** | Output mode | update | Se√ß√£o 4.5, c√©lula 25 |
| **ES Consumer** | Batch size | 30 documentos | Se√ß√£o 6.2, c√©lula 38 |
| **ES Consumer** | Dura√ß√£o | 120 segundos | Se√ß√£o 6.3, c√©lula 39 |
| **Elasticsearch** | √çndice | `wordcount-realtime` | Se√ß√£o 6.1, c√©lula 37 |
| **Kibana** | Auto-refresh | 10 segundos | Se√ß√£o 7.1, c√©lula 42 |

---

## üîß Tecnologias e Vers√µes

| Tecnologia | Vers√£o | Uso |
|------------|--------|-----|
| Apache Spark | 3.5.0 | Processamento de streaming |
| PySpark | 3.5.0 | API Python para Spark |
| Apache Kafka | 7.5.0 (Confluent) | Sistema de mensageria |
| Elasticsearch | 8.12.0 | Indexa√ß√£o e busca |
| Kibana | 8.12.0 | Visualiza√ß√£o de dados |
| kafka-python | latest | Cliente Kafka para Python |
| elasticsearch-py | latest | Cliente ES para Python |
| Docker Compose | - | Orquestra√ß√£o de containers |

---

## üéØ Diferenciais da Implementa√ß√£o

### 1. Execu√ß√£o 100% Autocontida
- ‚úÖ Todas as opera√ß√µes em c√©lulas do notebook
- ‚úÖ Nenhuma depend√™ncia de scripts externos
- ‚úÖ Setup de infraestrutura via c√©lulas Python
- ‚úÖ Producer e Consumer em threads dentro do notebook
- ‚úÖ Monitoramento e estat√≠sticas integrados

### 2. Justificativa T√©cnica Robusta
- ‚úÖ An√°lise detalhada das limita√ß√µes do Discord
- ‚úÖ Compara√ß√£o entre alternativas
- ‚úÖ Refer√™ncias oficiais (Discord API, Kafka Docs)
- ‚úÖ Explica√ß√£o das vantagens da solu√ß√£o escolhida

### 3. Pipeline Completo Kafka ‚Üí Spark ‚Üí ES
- ‚úÖ Producer sint√©tico realista
- ‚úÖ Processamento com janelas temporais
- ‚úÖ Watermark para eventos atrasados
- ‚úÖ Consumer otimizado com batch indexing
- ‚úÖ Queries m√∫ltiplas (output + debug)

### 4. Instru√ß√µes Kibana Detalhadas
- ‚úÖ Passo a passo com screenshots mencionados
- ‚úÖ 3 alternativas ao Tag Cloud
- ‚úÖ Configura√ß√£o de dashboard completo
- ‚úÖ Auto-refresh para tempo real
- ‚úÖ Verifica√ß√£o via API

### 5. Monitoramento e Valida√ß√£o
- ‚úÖ Verifica√ß√£o de sa√∫de de todos os servi√ßos
- ‚úÖ Contadores de mensagens e documentos
- ‚úÖ Estat√≠sticas finais consolidadas
- ‚úÖ Top 20 palavras mais frequentes
- ‚úÖ Visualiza√ß√£o de amostra

---

## üìù Como Executar

### Pr√©-requisitos
```bash
cd /home/edilberto/pspd/atividade-extraclasse-2-pspd/spark
docker-compose up -d
```

### Execu√ß√£o do Notebook
1. Abrir: `spark/notebooks/B2_SPARK_STREAMING_COMPLETO.ipynb`
2. Executar c√©lulas sequencialmente (Shift+Enter)
3. Aguardar 3-4 minutos para acumular dados
4. Acessar Kibana: http://localhost:5601
5. Seguir instru√ß√µes da Se√ß√£o 7 para criar dashboard
6. Capturar screenshots

### Ordem de Execu√ß√£o
1. **Se√ß√£o 1-2:** Leitura e contexto (markdown)
2. **Se√ß√£o 2:** Configura√ß√£o e inicializa√ß√£o Docker
3. **Se√ß√£o 3:** Teste do producer (20 mensagens)
4. **Se√ß√£o 4:** Setup do pipeline Spark
5. **Se√ß√£o 5:** Iniciar producer em background
6. **Se√ß√£o 6:** Criar √≠ndice ES e iniciar consumer
7. **Se√ß√£o 7:** Criar visualiza√ß√µes no Kibana
8. **Se√ß√£o 8:** Parar queries e gerar estat√≠sticas

### Tempo Estimado
- Setup inicial: 2-3 minutos (Docker + Kafka + ES/Kibana)
- Execu√ß√£o pipeline: 3-4 minutos (producer + streaming + indexing)
- Cria√ß√£o dashboard Kibana: 5-7 minutos (manual)
- **Total:** ~15 minutos

---

## üéì Conclus√µes

### Objetivos Alcan√ßados

‚úÖ **Entrada via Kafka com Justificativa**
- Alternativa ao Discord implementada e justificada tecnicamente
- Producer sint√©tico realista e configur√°vel
- Documenta√ß√£o completa da implementa√ß√£o

‚úÖ **Pipeline Spark Structured Streaming**
- Leitura, processamento e escrita em Kafka
- Agrega√ß√µes com janelas temporais
- Watermark para eventos atrasados

‚úÖ **Sa√≠da com Elasticsearch**
- Consumer implementado com batch indexing
- √çndice otimizado com mapping correto
- Valida√ß√£o de documentos indexados

‚úÖ **Dashboard Kibana**
- Instru√ß√µes detalhadas para Tag Cloud
- 3 alternativas documentadas
- Configura√ß√£o de dashboard completo
- Verifica√ß√£o via API

‚úÖ **Execu√ß√£o Autocontida**
- 100% das opera√ß√µes em c√©lulas do notebook
- Nenhum script externo necess√°rio
- Infraestrutura gerenciada via Docker

### Pr√≥ximos Passos

**√önico item pendente:**
- [ ] Capturar screenshots do dashboard Kibana (a√ß√£o manual)
  - `resultados_spark/kibana_dashboard_wordcloud.png`
  - `resultados_spark/kibana_tagcloud_detail.png`

### Extens√£o Implementada: An√°lise de Sentimentos (ML)

‚úÖ **Se√ß√£o 8.4 do Notebook - OPCIONAL**

**Biblioteca:** VADER (Valence Aware Dictionary and sEntiment Reasoner)

**Refer√™ncia Principal:**
> Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14).

**Funcionalidades Implementadas:**
- Instala√ß√£o e teste de VADER
- Producer com mensagens de sentimento variado (positivo, neutro, negativo)
- Consumer que analisa sentimento em tempo real
- Indexa√ß√£o no Elasticsearch com scores de sentimento
- Instru√ß√µes para visualiza√ß√µes no Kibana (Pie Chart, Line Chart)

**Diferencial:**
- Integra√ß√£o nativa com Kafka Streaming (n√£o batch)
- An√°lise em tempo real durante indexa√ß√£o
- Pipeline 100% em notebook
- Dataset balanceado com 18 mensagens de sentimentos variados

**Como Executar:** 
Descomente as c√©lulas da Se√ß√£o 8.4.6 do notebook para testar an√°lise de sentimentos.

### Melhorias Futuras Adicionais

- Filtro de stop words (the, and, is, etc.)
- Agrega√ß√µes por usu√°rio e per√≠odo do dia
- Alertas no Kibana para palavras ou sentimentos espec√≠ficos
- Kafka com replica√ß√£o para HA
- Modelos deep learning (BERT/Transformers)

---

## üìö Refer√™ncias

1. [Apache Spark Structured Streaming Programming Guide](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
2. [Kafka Documentation - Streams](https://kafka.apache.org/documentation/streams/)
3. [Elasticsearch Python Client](https://elasticsearch-py.readthedocs.io/)
4. [Kibana Visualizations Guide](https://www.elastic.co/guide/en/kibana/current/dashboard.html)
5. [Discord Developer Documentation - Rate Limits](https://discord.com/developers/docs/topics/rate-limits)
6. [PySpark SQL Functions](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html)

---

**Implementado por:** Edilberto Cantuaria  
**Data:** 29 de Novembro de 2025  
**Disciplina:** PSPD - UnB  
**Status:** ‚úÖ COMPLETO (pendente apenas screenshots manuais)
